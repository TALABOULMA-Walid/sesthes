\chapter{\label{ch:2-bkgnd}Background}

\minitoc

This chapter describes fundamental concepts and gives literature review about research topics that are involved in this thesis. Topics covered include modeling and simulation, co-simualtion, parallel computing, scheduling in the context of parallel computing, and parallelization approaches related to (co-)simulation. 

\section{\label{sec:MnS}Modeling and Simulation}

The design of complex systems impose the study of their behavior before building them with the objective of allowing preliminary evaluation, tuning and possibly redesign of the solution. Simulation has proven successful in responding to this need and became an indisputable step in the design process of complex systems. Simulation is an effective way for cost reduction since it allows correcting design errors before building the system. Simulation is performed by providing models which describe the system and then bringing these models to life by running them in order to imitate, on a computer, the behavior of the simulated system over time.   

\subsection{Systems}

Before detailing the concepts and methods of modeling and simulation of systems, it is important to understand what is meant by a system. A system is defined as a set of interacting parts which form a complex whole and operate towards a common goal. 

In order to have clearer understanding, the notion of a system should be conceived in the scope of the context that it is used in. In engineering domains, in addition to the definition given above, a system can be seen as an entity which consumes inputs and produces outputs from and to the environment, and is characterized by an internal state. The state of the system is affected by the inputs that it consumes, and, in turn, affects the produced outputs. Figure \ref{fig:system} illustrates this view as usually found in block diagrams where $u$ represents the input of the system, $y$ the output, and $x$ the internal state.

\begin{figure}[phbt]
\centering
\includestandalone{figures/system}
\caption{A block diagram representation of a system.}
\label{fig:system}
\end{figure}

A kind of systems that falls within the scope of this thesis is known as Cyber-Physical Systems (CPS) \cite{lee:2016}. CPS consist of a combination of tightly or loosely interacting computational elements and physical processes. The computational elements are called embedded systems or controllers and are used to control the physical processes. They are interfaced with the physical processes through sensors and actuators. The aim of the controller is to bring the physical process to a desired state by sending digital control data. If the physical process does not in turn send back data to the controller, the system is referred to as \textit{open loop control}. Alternatively, the controller's behavior is possibly adapted to the change in the state of the physical process which sends feedback data. The term \textit{closed loop control} is used to refer to such interaction between the controller and the physical process. Basically, an error, which is the divergence between the aimed behavior, called reference, and the actual behavior of the physical process is measured and corrected. Figure \ref{fig:feedb} shows a basic example of a CPS with feedback control. It is common that CPS contain multiple feedback loops and involve simple or sophisticated networks that are used for the communication between the different parts of the CPS. A Digital-to-Analog Converter (DAC) is used to convert the data produced by a controller and consumed by a physical process. Conversely, an Analog-to-Digital Converter (ADC) is used to convert the data produced by a physical process and consumed by a controller. 

\begin{figure}[phbt]
\centering
\includestandalone{figures/feedbackloop}
\caption{Feedback control of a physical process.}
\label{fig:feedb}
\end{figure}  

Areas where CPS can be found are as important as automotive, aerospace, manufacturing, transportation and many others. The diversity of the involved disciplines makes the process of building CPS challenging, costly and time consuming.

\subsection{Modeling}

Modeling a system consists in creating a mathematical abstraction of its behavior. The first step is to choose a modeling formalism. This choice depends on the properties of the system, the objective of the simulation, and the aimed level of detail in the simulation. For instance, models can be built using continuous time variables to represent continuous dynamics of a physical process. Such mathematical models consist of a set of differential equations which describe the continuously changing physical quantities of a process such as electrical circuits, fluid dynamics, chemical reactions, etc. Other systems feature a behavior which evolves between a finite set of states. These systems can be modeled using formalisms such as DEVS (Discrete Event System Specification) \cite{zeigler:2000}, Statecharts \cite{harel:1987}, and Petri nets \cite{petri:1962}. Finally, hybrid modeling allows the modeling of systems with both continuous variables and discrete states. In other words, the system jumps between discrete states and while it is in a certain state, it features a continuous behavior, {\em i.e.} its quantities change continuously. 

In this thesis, we focus on the modeling of dynamical systems using differential equations. A differential equation expresses a variable as a function of its derivatives. In the modeling of dynamical systems, the variables are the physical quantities and the derivatives express their rates of change. A differential equation is called Ordinary Differential Equation, abbreviated ODE, if it involves ordinary derivatives of the variables with respect to an independent variable (usually the time in the modeling of dynamical systems). The ordinary derivative consists in computing the derivative of the function allowing all variables to vary. The term ordinary is used in contrast with the term Partial Differential Equation presented below. Equation \ref{eq:ode} is an ODE where $x$ is the vector of the variables of interest called the state variables, $\dot{x} = \frac{dx}{dt}$ is the vector of the time derivatives of the state variables, $t$ is the time (the independent parameter), and $f$ is a given function.

\begin{equation}
 0 = f(\dot{x},x,t) \equiv f(\frac{dx}{dt},x,t)
\label{eq:ode}
\end{equation}

A differential equation is called Partial Differential Equation, abbreviated PDE if it involves unknown functions and their partial derivatives. A partial derivative of a function is its derivative with respect to one variable while holding the other variables constant. Equation \ref{eq:pde} shows such PDE where $x_1,x_2,\dots, x_n$ are the parameters, $y=y(x_1,x_2,\dots, x_n)$ is the unknown function, $\frac{\partial y}{\partial x_i}: 1 \leq i \leq n$ are the partial  derivatives of $y$, and $f$ is a given function.

\begin{equation}
0 = f\biggl(x_1,x_2,\dots, x_n,y,\frac{\partial y}{\partial x_1},\frac{\partial y}{\partial x_2},\dots,\frac{\partial y}{\partial x_n}\biggl)
\label{eq:pde}
\end{equation} 

A Differential Algebraic Equation, abbreviated DAE, is a system of equations which involves algebraic equations in addition to differential equations. A DAE can be written in the form shown in equation \ref{eq:dae} where $f$ represents differential equations involving derivatives of variables and $g$ represents algebraic equations which do not contain derivatives.

\begin{equation}
\begin{aligned}
&0 = f(\dot{x},x,t) \equiv f(\frac{dx}{dt},x,t) \\
&0 = g(x,t)
\end{aligned}
\label{eq:dae}
\end{equation}
  
In this thesis, we are particularly interested in modeling dynamical systems using ODEs. Typically, such systems are hybrid dynamical systems modeled using hybrid ODEs. These systems exhibit continuous behavior interspersed with jumps triggered by some events. There are two kinds of events: Events which occur at a particular instant in time are called \textit{time events}. The other kind of events, called \textit{state events} or \textit{zero-crossing}, arise as a result of the value of a state variable crossing a specific threshold. Time events are easier to handle than state events since they occur at known instants in time. A classic example of such hybrid dynamical systems is the bouncing ball model where a ball is dropped from a certain height above the ground. The ball falls with a velocity subject to gravity and bounces when it hits the surface. Equation \ref{eq:bb} gives a hybrid system of equations which describes the behavior of the bouncing ball where $x$ is the position of the ball (height), $v$ its velocity, $g$ the gravity constant, and $\gamma$ the coefficient of restitution. The first and second time derivatives of $x$, $\dot{x} = \frac{dx}{dt}$ and $\ddot{x} = \frac{d^2x}{dt^2}$ represent the velocity and the acceleration of the ball respectively. 

\begin{equation}
\begin{aligned}
&\dot{x} = v\\
&\ddot{x} = -g\ \text{if}\ x > 0\\
&\dot{x} := -\gamma \dot{x}\ \text{if}\ x = 0 
\end{aligned}
\label{eq:bb}
\end{equation}  

The bouncing ball model exhibits a continuous behavior when $x > 0$ and discontinuities occur at bounces, i.e. when $x = 0$, where the velocity of the ball is inverted and scaled down by a factor equal to $\gamma$. In other words, the motion of the ball changes from downward to upward. This hybrid dynamical system can be modeled using a hybrid automaton as shown in Figure \ref{fig:bbautomaton}.

\begin{figure}[phbt]
\centering
\includestandalone{figures/bbautomaton}
\caption{Hybrid automaton of the bouncing ball system.}
\label{fig:bbautomaton}
\end{figure}

The discrete dynamics found in hybrid dynamical systems should be distinguished from the discrete nature of the controllers. The controllers are digital systems, hence, discrete systems. Control laws, i.e. the algorithms of control can be modeled in the continuous domain. However, since these laws are intended to be implemented on computers, a conversion from the continuous to the discrete domain is needed in order to implement them as controller software. When simulated (see next section) with the physical process, a control law that is modeled in the continuous domain is richer in terms of the information it gives about the controller behavior than its discrete counterpart. Also, continuous control laws allow better optimization of specific criteria that are of interest. The discrete control laws obtained through discretization of the continuous control laws are simulated with the physical processes in order to assess the effects of the discretization and, finally, implement the controller software.

\subsection{Simulation}

Given a model of the system under study, the simulation consists in running this model in order to produce and plot, on a computer, data consisting in time varying values of the quantities of interest. These data are used in order to assess different aspects about the functioning of the system. Technically speaking, running a model which consists of a set of ODEs means solving these equations. In practice, it is not possible to find the solution of such equations analytically which imposes the use of numerical methods to solve them. Such numerical methods, called solvers, are based on the principle of discretization of the time $t$. This means that the values of the state variables $x(t)$ of an ODE in the form of equation \ref{eq:ode} evolve between discrete points of time, called \textit{time steps}, $(t_k, t_{k+1}, \ldots)$ instead of an evolution in continuous time $t \in \mathbb{R}^+$. The distance between two time steps is called the \textit{time step size} or the \textit{integration step size}. The smaller is the integration step size, the more accurate is the numerical resolution of the equations, i.e. the closer it is to the exact solution. However, reducing the integration step size requires more computations and, thus, slows down the execution of the solver. A tradeoff has to be made according to the desired quality and computation speed.

The discretized time can be written as: $t_k = k \times h$ where $h$ is the integration step size and $k \in \mathbb{N}$. The solver computes a sequence: $x_{k+1} = F(x_k,t_k)$ where $x_k$ is the value of the variable $x$ at $t_k$, the $k^{th}$ time step and $F$ is the solver or the integration function. Starting from the initial time $t_0$ and having the initial condition $x_0$, which is the value of $x$ at time $t_0$, the numerical resolution consists in computing approximate values of the quantity $x$ repeatedly with respect to the discretized time. The time step $h$ has to be chosen in such a way that the dynamics of the simulated system are well captured. When the system exhibits dynamics heterogeneity, e.g. fast transients and slow evolutions of the state variables, a fixed time step becomes less efficient. It is therefore  more efficient to use a variable time step. A solver with variable step controls the step size using a feedback loop on the error. The step size is adapted according to an estimation of the error. 

Solvers are characterized by a number of properties (e.g. order, explicit/implicit, fixed/variable integration step size, convergence, speed, \ldots) which should be taken into consideration when choosing a solver for a specific problem. %Overall, it is always desirable to choose a solver that is reliable, robust and fast.

As an example, the simulation of the bouncing ball model represented in Figure \ref{fig:bbautomaton} produces the plots shown in Figure \ref{fig:bbsim}. The time-varying position and velocity of the ball as it alternates between downward and upward movements are shown in Figure \ref{fig:bbpos} and Figure \ref{fig:bbve} respectively.

\begin{figure}[phtb]
\centering
\begin{subfigure}{\textwidth}
  \centering
  \includestandalone{figures/bbposition}
  \caption{Position}
  \label{fig:bbpos}
\end{subfigure}

\begin{subfigure}{\textwidth}
  \centering
  \includestandalone{figures/bbvelocity}
  \caption{Velocity}
  \label{fig:bbve}
\end{subfigure}
\caption{Trajectories obtained from the simulation of the bouncing ball model}
\label{fig:bbsim}
\end{figure}

Quantized State System (QSS) methods \cite{kofman:2001} offer an alternative to modeling an simulation methods based on time discretization. Their principle is based on discretizing the state and considering the time as continuous. The resolution consists in solving for the time when the state changes by a quantum. These methods are out of the scope of this thesis. %This is because a part of this thesis targets real-time co-simulation which requires the time base to be known. Since QSS methods consider the time as an unknown continuous variable, they are not suitable for real-time co-simulation.  

\subsection{Co-simulation}

Complex systems may involve heterogeneous interacting parts. For instance, In a CPS, the controlled physical process constitutes a multi-physics system and is modeled in the continuous time domain using (hybrid) Ordinary Differential Equations (ODEs). On the other hand, because they are implemented on embedded computers, numerical laws that control the physical process may be modeled in the discrete time domain. For such systems, it becomes necessary to do the modeling at the subsystem level, sometimes without a detailed view about the other subsystems. Models are then coupled together in order to perform simulation at the system level, known as co-simulation. In co-simulation, the different models are simulated in a black-box fashion and an orchestration of their interactions has to be ensured. The interactions between the involved models consist in data exchange.

Co-simulation is an alternative approach to monolithic simulation where a complex system is modeled as a whole using differential equations and simulated by numerically solving these equations. Co-simulation has a number of advantages over the monolithic approach. It allows modeling each part of the system using the most appropriate modeling tool instead of using a single one. Also, it allows a better intervention of the experts of different fields at the subsystem level. Furthermore, co-simulation facilitates the upgrade, the reuse, and the exchange of models. 

In co-simulation of models based on ODEs, the equations of each model are integrated using a solver separately. 
Models exchange data by updating their inputs and outputs at fixed points in time called \textit{communication steps}. The distance between two communication steps is referred to as \textit{communication step size} and denoted $H$. The communication step size associated with a model is a multiple of the integration step size of the model and defines the rate of communication (data exchange) of this model. It does not make any sense to use a communication step size that is smaller than the integration step size because communication should only be performed at points corresponding to integration steps. Thus, the communication step size should be at least equal to the integration step size. Using a communication step size that is a multiple of the integration step size is interesting when the inputs or the outputs of the model don't need to be updated at every integration step. For instance, if at one out of two integration steps, the model consumes new input values, its communication step size can be set to two times its integration step size. Therefore, the equations of the model are computed at every integration step, and its inputs and outputs are updated at every communication step. 
Figure \ref{fig:cosim} shows the evolution of time and data exchange in a co-simulation of two models A and B. In this example, the equations of model A are solved using a fixed step size $h_A$ whereas the equations of model B are solved using a variable step size $h_B$. The communication step size $H $ is considerably larger than both integrations step sizes, allowing fast progress of the integration of the equations by restricting the data exchange to occur at communication steps only. Between communication steps, each model considers that the values of data produced by the other model are held constant. Another alternative is to estimate these values by employing extrapolation techniques \cite{benkhaled:2014_context,benkhaled:2017}.

\begin{figure}[phbt]
\centering
\includestandalone{figures/cosim}
\caption{Time evolution and data exchange between two models during co-simulation.}
\label{fig:cosim}
\end{figure}

For larger co-simulations involving more models, different communication step sizes may be associated with different models. In this case, we talk about \textit{multi-rate} co-simulation.

In this thesis, we are interested, in particular, in co-simulations that are compliant with the Functional Mock-up Interface (FMI) standard \cite{fmi:2014}, presented hereafter. There exist other standards which target the coupling of simulators, e.g. the High-Level Architecture (HLA) \cite{ieee1516:2012}. The HLA is an IEEE standard developed by the U.S. Modeling and Simulation Coordination Office (M\&S CO)\footnote{www.msco.mil}. We are interested in the FMI standard because it is adopted by many modeling and simulation tools and is becoming the state of the art standard for co-simulation, thanks to the different possibilities of simulators and models coupling that it offers.

In the context of CPS which contain embedded systems controlling physical processes, different kinds of co-simulation, presented below, can be performed depending on the stage of the controller design.

\subsubsection{Model-in-the-Loop}

At an early stage of the controller design, Model-in-the-Loop (MiL) co-simulation is performed. In MiL, the model of the controller is included with the model of the controlled physical process in a co-simulation in order to test and validate the functioning scenarios of the controller. By using a system model, MiL aids in the design of control algorithms and also the investigation of design concepts. Once the functions of the control algorithm are specified, the controller software can be implemented.

\subsubsection{Software-in-the-Loop}

In the next stage, the controller software can be implemented to perform Software-in-the-Loop (SiL) co-simulation. The controller software code can be generated from the controller model. It is then integrated with the simulated models and executed on the computer that runs the simulation. SiL is an inexpensive approach to perform realistic tests of the controller’s performance without the need for using a special hardware. It is common to move back and forth between the MiL and the SiL stages to make necessary rectifications if design flaws are detected.

\subsubsection{Hardware-in-the-Loop}

After the verification of the controller software, the next stage consists in performing Hardware-in-the-Loop (HiL) co-simulation. In HiL, the controller software is implemented on the controller hardware (e.g. Electronic Control Unit) which is connected to the computer that runs the simulation of the physical process. HiL must run in real-time in order to imitate the real interactions between the controller and the physical process. If any problems are detected, one can go back to SiL or MiL stage to make necessary corrections. Lamberg and W{\"a}ltermann enumerate the following advantages of HiL \cite{lamberg:2000}:

\begin{itemize}

\item The controller algorithm can be tested in an early stage of the development process, allowing early potential corrections and tuning.

\item HiL is an efficient alternative for expensive field trials, experiments in borderline zones and hazardous situations.

\item Parameters can be tuned in order to perform tests under unusual conditions, e.g. extreme weather conditions. 

\item Failures that could lead to catastrophic damages in the real system can be tested and corrected systematically.  

\item If needed, the tests can be reproduced repeatedly and automatically with high precision.

\end{itemize}

Figure \ref{fig:mbd} gives a view of the different types of co-simulation performed as part of the process of controller design.

\begin{figure}[phbt]
\centering
\includestandalone{figures/mbd}
\caption{Different types of co-simulation involved in the process of controller design.}
\label{fig:mbd}
\end{figure}

Coupling models and performing co-simulation presents many technical challenges. Some attempts have been made to establish methods that allow easy coupling of models and running co-simulations. In the following, we present FMI, a prominent industrial standard that was developed for model exchange and co-simulation.  

\subsubsection{The Functional Mock-up Interface Standard}

The Functional Mock-up Interface (FMI) is a tool-independent and open standard designed in the context of the European ITEA MODELISAR project\footnote{itea3.org/project/modelisar.html} and is currently developed and maintained by the Modelica Association\footnote{www.modelica.org/association/} which promotes the Modelica language (see Section \ref{lngtoolsMS}). The FMI standard was developed in order to facilitate the co-simulation of dynamical systems, such as CPS. It provides specifications in order to enable the exchange and the co-simulation of heterogeneous dynamical models that may be developed by different tools. A modeling tool that supports FMI can export a model as a Functional Mock-up Unit (FMU) which can be used in co-simulation environments. FMI defines interfaces for the involved models to allow their co-simulation.

%\begin{figure}[h]
%\centering
%\captionsetup{justification=centering}
%\includegraphics{figures/fmifigure}
%\caption{Vision on how FMI can be used in the automotive domain\footnotemark.} 
%\label{fig:fmifigure}
%\end{figure} 


An FMU is a package that encapsulates different files:

\begin{itemize}
\item An XML file that contains, among other data, the definition of the different variables of the models and the description of the dataflow between these variables. 
\item Model functions: Standardized C functions that are used to create instances of the FMU and run them. The functions can be provided as platform dependent binaries (e.g. DLL files) or as C source code.
\item Documentation: Optional files that contain documentation about the model.
\end{itemize}

The FMI standard is organized in two parts:
\begin{itemize}
\item FMI for Model Exchange:
This specification provides interfaces and defines how model equations should be encapsulated in components. It allows solving each model independently using custom solvers. Accessing and computing the equations is done through standardized function calls. Figure \ref{fig:fmimdlexg} illustrates the principle of FMI for Model Exchange.

\begin{figure}[phbt]
\centering
\includestandalone{figures/fmimdlexg}
\caption{FMI for Model Exchange.}
\label{fig:fmimdlexg}
\end{figure}

\item FMI for Co-Simulation:
This specification defines interfaces between a master algorithm and slave models. It is intended to couple different simulators (models with their solvers) in a co-simulation environment. Figure \ref{fig:fmicosim} illustrates the principle of FMI for Co-Simulation.

\begin{figure}[phbt]
\centering
\includestandalone{figures/fmicosim}
\caption{FMI for Model Co-Simulation.}
\label{fig:fmicosim}
\end{figure} 
\end{itemize}

In the context of FMI, we talk about model export and import. Model export means that a model is developed in one tool and then shipped as an FMU. Model import refers to using an FMU in a co-simulation environment different than the tool that was used to develop the FMU. In Figure \ref{fig:fmimdlexg} and Figure \ref{fig:fmicosim}, the different FMUs are imported into and executed within the co-simulation environment.

%Figure shows the state machine of the supported calling sequences from a master algorithm to a slave.

%\begin{figure}[h]
%\centering
%\captionsetup{justification=centering}
%\includegraphics[scale=0.6]{figures/callingsequence}
%\caption{Calling sequence of Co-Simulation C functions in form of an UML 2.0 state machine} 
%\label{fig:callingsequence}
%\end{figure}  

%The High Level Architecture (HLA) \cite{} is another standard for distributed simulation.
 

\subsection{Co-simulation under Real-time Constraints}

In the design process of complex systems, it is often necessary to test the behavior of the system or a part of the system as it would be produced by the real system. Therefore, the co-simulation is executed under real-time constraints such that the progress of the simulated time matches the real-time. For example, if temperature takes three minutes to reach $25$° in the real system, the simulated temperature has to take three minutes as well to reach the same value. Co-simulation under real-time constraints has to be executed such that the simulated time is advanced at the same speed as real-time.

A typical application of co-simulation under real-time constraints is HiL co-simulation. The key advantage of co-simulation under real-time constraints is that it allows testing the controller under realistic conditions even if the physical process is not available.

Roughly speaking, the difference between co-simulation under real-time constraints and co-simulation without real-time constraints is related to the notion of results validity. For co-simulation without real-time constraints, one seeks to obtain results as soon as possible. The validity of the results depends only on their numerical accuracy. For co-simulation under real-time constraints, the validity of results depends not only on their numerical accuracy but also on their availability time, i.e. they have to be available within specific time \textit{deadlines}. If such deadlines are missed, the results are considered invalid even if their values are correct from a numerical standpoint.

Figure \ref{fig:rtcosim} illustrates the time evolution of a co-simulation under real-time constraints in comparison to accelerated co-simulation without real-time constraints. For the former, during the resolution of the differential equations, the value of each variable $x$ is computed at every time step. The computation of $x_{n+1}$, the value of $x$ at time step $t_{n+1}$, cannot start before the value of $x_n$ is computed as the computation of $x_{n+1}$ depends on the value of $x_n$. If the time required to compute the value of $x_{n+1}$ exceeds the step size, the real-time constraints are violated which makes the co-simulation invalid. This is known as an \textit{overrun}. In the field of real-time systems, we talk also about \textit{deadline miss}. In the context of co-simulation under real-time constraints, the deadline of a variable computation is the time step by which the value of the variable has to be provided, e.g. time step $t_n$ for the computation of $x_n$.

A co-simulation under real-time constraints is executed repeatedly. The execution is driven by real-time periods related to data exchange between the simulated part and the real part, e.g. the controller. This period can be different (usually greater) than the integration step sizes used in the co-simulation. In this case, not all computations are required to meet their deadlines. Instead, we seek \textit{rendezvous} points where time steps and real-time periods match. Only the computations whose deadlines correspond to these points must not overrun. Hence, a co-simulation can be guaranteed to satisfy real-time constraints even if the rest of the computations miss their deadlines. Note that this is the main reason we use the term co-simulation under real-time constraints instead of real-time co-simulation. In fact, the latter implies that all computations are subject to real-time constraints.   

\begin{figure}[phbt]
\centering
\captionsetup{justification=centering}
\includestandalone{figures/rtcosim}
\caption{Comparison of accelerated co-simulation and co-simulation under real-time constraints.}
\label{fig:rtcosim}
\end{figure} 

\subsection{\label{lngtoolsMS}Languages and Tools for Modeling and Simulation}

Building models of systems can be done manually and then transformed into software using general purpose programming languages such as C. However, this approach is not efficient in practice, especially when the modeled system is complex and changes may be required in the model. Many tools and languages for modeling and simulation have been developed in order to facilitate and make the modeling and simulation more efficient. Such tools allow the user to specify an equation-based model in a straightforward manner and come with built-in solvers. Below, we present a non exhaustive list of tools and languages for modeling and simulation.

%\begin{figure}[h]
%\centering
%\captionsetup{justification=centering}
%\includegraphics[scale=0.5]{figures/mipsxmod}
%\caption{Example of co-simulation models in xMOD.} 
%\label{fig:mips}
%\end{figure} 

\subsubsection{MATLAB Simulink}
Simulink\footnote{www.mathworks.com/products/simulink}, developed by The Mathworks is a graphical modeling environment. Simulink can be used in the  process of designing embedded systems. It allows the simulation of embedded systems with the controlled physical processes. Models are built graphically in Simulink using block diagrams. In addition, Simulink is integrated in MATLAB which allows the incorporation of MATLAB functions in Simulink models. Finally, Simulink enables automatic code generation from models.

\subsubsection{Modelica}
Modelica \cite{modelica:2017} is an object-oriented equation-based language for the modeling of complex physical systems developed by the Modelica Association. Modelica allows the modeling of physical systems by writing a set of equations. Modelica adopts an acausal approach, i.e. the direction of the signal is not specified in the model. The simulator has to perform symbolic manipulations in order to define inputs and outputs and find an order of execution for these equations. There exist several tools that are based on the Modelica language.

OpenModelica\footnote{www.openmodelica.org} is an open-source modeling and simulation environment based on the Modelica language. It is developed and maintained by the Open Source Modelica Consortium (OSMC). OpenModelica supports the FMI for Model Exchange standard.

Dymola\footnote{www.3ds.com/products-services/catia/products/dymola}, developed by Dassault Syst\`emes AB, is a modeling and simulation environment based on the Modelica modeling language. Dymola supports the FMI standard and allows interfacing with other tools such as Simulink.

\subsubsection{LMS Imagine.Lab Amesim}
LMS Imagine.Lab Amesim\footnote{www.plm.automation.siemens.com/en\_us/products/lms/imagine-lab/amesim} is a modeling and simulation software developed by Siemens PLM Software. It can be used for the modeling and simulation of mechatronic systems. It is based on the Modelica modeling language. It is oriented towards the modeling of complex physical systems instead of controller design. LMS Imagine.Lab Amesim provides libraries containing collections of components that can be loaded and connected by the user to build models. For simulation, LMS Imagine.Lab Amesim automatically selects a solver that is adapted to the problem. It supports the FMI standard.

\subsubsection{xMOD}
xMOD\footnote{www.xmodsoftware.com} is the modeling and co-simulation software developed by IFP Energies nouvelles. It supports the FMI standard and provides an environment for the integration of heterogeneous models built by different parties using different languages and tools. xMOD can execute models with different integration and communication step sizes. Also, it allows the co-simulation of models embedding different solvers or not. In the latter case, xMOD provides a list of different solvers from which the user can choose one for every model. xMOD does not replace original modeling and simulation tools. Instead, it promotes and facilitates their coupling and existence.

\subsubsection{DACCOSIM}

The Distributed Architecture for Controlled CO-SIMulation (DACCOSIM)\footnote{sourcesup.renater.fr/daccosim} is a co-simulation software developed and maintained by EDF Lab Paris-Saclay\footnote{www.edf.fr} and CentraleSup\'{e}lec\footnote{www.centralesupelec.fr}. It supports the FMI standard and allows distributed co-simulation of FMUs on multi-core architectures or clusters. DACOSSIM is able to execute FMUs with different fixed or variable integration steps. 

\subsubsection{CosiMate}

CosiMate\footnote{www.cosimate.com} is a co-simulation environment that enables distributed co-simulation. Multiple simulators can be executed on different computers and communicate over a network. CosiMate supports the FMI standard, interfacing with Simulink, and several languages like Modelica, C++, and Java.

\subsubsection{Hopsan}
Hopsan\footnote{www.iei.liu.se/flumes/system-simulation/hopsan?l=en} is a free multi-domain system co-simulation tool developed at the division of Fluid and Mechatronic Systems at Link\"oping university. Hopsan supports the FMI standard and model export to Simulink.

%\subsection{Tools and Languages for Real-time Simulation}

The additional timing constraints found in real-time simulation require the use of adapted tools. Many real-time simulation tools are developed in such a way to run the simulated part on special dedicated hardware that provides an execution fast enough to ensure real-time constraints. Other solutions tend to enable real-time co-simulation using general purpose computers equipped with Real-Time Operations Systems (RTOS). In \cite{faruque:2015}, the authors give a list of the available real-time simulation tools and detail their characteristics. In the following, we present a non exhaustive list of tools for real-time simulation.

\subsubsection{Simulink Coder}

MATLAB/Simulink offers the Simulink Coder solution for real-time simulation. Simulink Coder generates C/C++ executable code from Simulink models and MATLAB functions. The generated code can be used in a real-time simulation such as HiL testing. The generated code can be deployed with or without a RTOS. Simulink Coder offers three execution modes. In the Single-Tasking Mode, the generated code is executed in a single thread. In the Multi-Tasking Mode, the user specifies sampling periods for parts of the generated code, called rates in Simulink Coder, which are executed and scheduled by a priority-based scheduler. The Asynchronous Mode allows specifying nonperiodic or asynchronous rates. Simulink Coder generates the necessary code to handle such rates.

\subsubsection{RT-LAB}

OPAL-RT\footnote{www.opal-rt.com}, a company specializing in real-time simulation, develops the RT-LAB real-time simulation software. RT-LAB transforms Simulink models into a real-time application by generating and compiling C code. The generated code can be run in parallel on multiple cores. OPAL-RT provides its own hardware targets for the execution of real-time simulation combining COTS parallel computing technologies. Its solution uses a Linux based RTOS.

\subsubsection{dSpace}

dSpace\footnote{www.dspace.com} features the Real-Time Interface (RTI). dSpace relies on Simulink as the modeling tool and uses RTI to extend Simulink Coder for automatic implementation of generated code by Simulink Coder on the real-time hardware of dSpace. An RTI library in Simulink allows adding blocks that implement I/O capabilities to Simulink models. The code generated by Simulink Coder from such models is prepared to be executed on dSpace hardware without manual editing of the code.

\subsubsection{RTDS}

Developed by RTDS Technologies\footnote{www.rtds.com}, RTDS is a real-time simulator of power systems. It consists of a custom hardware and a custom software. The hardware is composed of multiple chassis containing each a multi-core processor. The RTDS software is designed for interfacing with the RTDS hardware. It consists of several modules necessary for creating, tuning, loading a simulation into the RTDS hardware, and plotting and visualizing the results.

\subsubsection{Typhoon HiL}

Multiple hardware platforms are proposed by Typhoon HiL\footnote{www.typhoon-hil.com}. It offers a complete software solution comprising a schematic editor, a module for interfacing with Typhoon hardware, a test suite to run some pre-certification tests, and a power systems toolbox offering a variety of built-in models. Typhoon HiL targets primarily real-time HiL simulation of power systems. 


\section{Parallel Computing}

Parallel computing is a very important branch in the computing research and industry. It refers to the discipline that focuses on executing multiple computations simultaneously to solve one problem; thus, accelerating the total time of computation. Its basic idea is to divide a computational task into several sub-tasks that can be performed at the same time. From the beginning of the modern era of computing, computer software has been typically written for sequential execution. In order to solve a problem, an algorithm is designed as a sequence of instructions that are executed one after the other. In order to increase the computation power of computers, the dominant method has for long been frequency scaling. If a processor's frequency is increased, it means that it can execute more instructions per clock cycle and thus can execute a sequential program faster. Moore's law predicted that the number of transistors in a processor would double approximately every two years \cite{moore:1965}. This prediction proved correct for many years. However, frequency scaling is facing technological limits and the last decade witnessed a wide shift to multi-core processors among semiconductor manufacturers. %Moore's law can be considered to be still accurate since more transistors are still integrated in chips, not for frequency scaling but to add more processing elements. 
The rise of multi-core processors has caused the evolution of many parallel hardware and software technologies.

The main goal of parallel computing is to execute computer programs faster. The speedup obtained from the parallelization can be predicted using Amdhal's law \cite{amdahl:1967}. It states that for a program that is paralellized in order to be executed on multiple processors, the portion of the program that has to be executed sequentially limits limit the attainable speedup. The speedup is, therefore, not linear according to the number of processors and adding more processors does not make the program run faster than the portion of the program that has to be executed sequentially. The following formula gives the theoretical speedup computed using Amdahl's law:
\begin{equation}
S(n) = \frac{1}{(1-P) + \frac{P}{n}}
\end{equation}
$S(n)$ is the theoretical speedup, $P$ is the portion of the program that can be parallelized and $n$ is the number of processors. Figure \ref{fig:amdhal} shows the theoretical speedup of a program in function of the number of processors for different values of $P$. It shows for example that if $50\%$ of a program can be parallelized, the maximum possible speedup is 2, and if $95\%$ of the program can be prallelized, the maximum speedup is around 20.

\begin{figure}[phbt]
\centering
\captionsetup{justification=centering}
\includestandalone{figures/amdhal}
\caption{Theoretical speedup computed using Amdahl’s law for a program in function of the number of processors for different values of P.}
\label{fig:amdhal}
\end{figure} 

\subsection{Parallelism in Hardware}

A computer program consists in a set of instructions. The first computers were only able to execute programs sequentially, i.e. one instruction after another. Later, parallel computing was made possible thanks to the introduction of parallel computers. Parallel computers are of many types, some of which are adapted only to specific kinds of applications. Parallel computers can be classified according to different criteria. Below, we present the common classifications of parallel computers. 

\subsubsection{Flynn's Taxonomy}

The well-known Flynn's taxonomy \cite{flynn:1972} classifies computers according to instruction and data streams into the following categories:

\paragraph{Single Instruction Stream Single Data Stream (SISD)} This is the basic uniprocessor which does not exhibit any parallelism. The execution is sequential where a single instruction stream operates on a single data stream. Examples of such architecture are old desktop computers.

\paragraph{Single Instruction Stream Multiple Data Streams (SIMD)} A SIMD computer executes the same instruction stream on multiple data streams in parallel. A Graphics Processing Unit (GPU) is one example of SIMD architectures.

\paragraph{Multiple Instruction Streams Single Data Stream (MISD)} Multiple instruction streams are executed on a single data stream. For example, in fault-tolerant computing, the same operation is performed in parallel and the results of all the computations must be the same. Pipeline architectures belong to the MISD class.

\paragraph{Multiple Instruction Streams Multiple Data Streams (MIMD)} Different instruction streams are executed on different data streams in parallel. Examples of MIMD computers include multi-core architectures, grid computers, and supercomputers.

\subsubsection{Memory Models}

Flynn's taxonomy differentiates parallel computers based on their operational behavior. Another important classification of parallel computers is the one based on the organization of the memory.

\paragraph{Shared Memory}

In this class of parallel architectures, a common memory is shared among multiple processors. All processors access the same global shared memory by operating on a single address space. Communication between the processors is performed through shared memory variables. Shared memory multiprocessors have the advantage of low communication overhead thanks to the proximity of the memory to processors. Scalability is a disadvantage of shared memory multiprocessors as increasing the number of processors creates more traffic between the processors and the memory resulting in memory contention. The latter means conflict between multiple accesses to memory. In practice, shared memory architecture do not scale beyond 16 processors.  

There are two kinds of shared memory designs, Uniform Memory Access (UMA) and Non-Uniform Memory Access (NUMA). In the UMA design, the time needed to access the memory is the same for all the processors. This architecture is referred to as Symmetric Multiprocessor also. In the NUMA design, each processor has a local memory, and the shared memory is composed of these local memories. Time to access a specific memory region is not uniform for all processors. Processors access their local memories faster than the local memories of other processors.

\paragraph{Message Passing} In the message passing model, also known as distributed memory, each processor has its own memory. Each processor operates on a distinct address space and is only able to access its own memory. As the name suggests, communication between the processors is performed by explicitly passing messages. If a processor requires data from another processor, it explicitly sends a request to this processor and waits for its response. An advantage of the distributed memory architecture is the scalability. If the number of processors is increased, memory is increased also. A disadvantage of the distributed memory architecture is the time needed to passe messages between processors. This time becomes large in the case of a huge number of processors or long distances between the processors. A typical distributed memory computer is a set of standalone computers interconnected via a network, e.g. Ethernet.

\paragraph{Hybrid Memory}

It is possible to use both shared and distributed memory in a computer. In this hybrid model, shared memory processors are connected via a network to form a distributed memory architecture. This is the dominant memory architecture in supercomputers today.

\subsection{Parallelism in Software}

Much progress has been made in the design of parallel hardware. That being said, taking advantage of such architectures requires efficient ways for executing software on parallel hardware. A difficult yet integral step in this direction is the process of detecting the parallelism that is inherent in software. This parallelism can be classified into different categories based on the nature of computations that are performed. The main classes of software parallelism are the following:    

\subsubsection{Data parallelism}
Data parallelism is characterized by performing the same computation on a large set of data. If several processors are available, the data can be distributed across them and the same computation is executed on each processor. For instance a for-loop can be parallelized by distributing the iterations over multiple processors. The same body of the for-loop is executed on all the processors but operates on a different range of iterations on each processor. Data parallelism corresponds to the SIMD parallel hardware.

\subsubsection{Task parallelism}
In task parallelism, a program is divided into different computational tasks that are distributed across the processors to be performed in parallel. The challenge here is the question of how to divide the program efficiently so as to obtain the best speedup. In task parallelism, tasks can operate on different data sets. Usually, data dependence exists between the tasks. For instance, the result of one task is needed as input by another task. Such dependence reduces the parallelism. Task parallelism corresponds to the MIMD parallel hardware.

\subsubsection{Pipeline Parallelism}

Pipeline parallelism combines data and task parallelisms. Multiple tasks operate on streams of data and are executed repeatedly in a sequence. Each task takes its input from the preceding task and produces output to the next task. When a task finishes processing a data element it passes it to the next task and starts processing a new data element even if the next task has not finished processing. Pipeline processing is common in streaming applications such as video streaming. Pipeline parallelism corresponds to the MISD parallel hardware. 

\subsection{Parallel Programming}

In order to efficiently map software parallelism on hardware parallelism, many parallel programming libraries, APIs, and standards have been developed. Basically they differ according to the targeted type of memory. In the following, we define two fundamental concepts found in parallel programming: \textit{processes} and \textit{threads}. Then, present parallel programming models.

\subsubsection{Process}

A process is an instance of a program. It is characterized by the executable code of the program and its context of execution including a unique process identifier, a memory space, values of the processor's registers, and other system resources. A program is a set of instructions and a process is the actual execution of these instructions. A process contains one or multiple threads (see below). The operating system offers Inter-Process Communication (IPC) mechanisms to handle communication between multiple processes.

\subsubsection{Thread}

A thread is a unit of execution within a process. Multiple threads can exist within a single process and be executed in parallel. Threads within the same process share the same memory space and the same code. Also, since they share variables, they can communicate directly, in contrast to processes which use IPC. Nevertheless, each thread has its own context including a unique thread identifier, values of the processor's registers, and a call stack.

Let's now present the different parallel programming models with some examples of libraries and standards that follow such models.

\subsubsection{Shared Memory Programming}

Shared memory programming is based on threads. Multiple threads are created and executed on multiple processors. The programmer does not need to worry about the communication between threads as this is done implicitly via shared variables. Threads may have private variables that are not shared with the other threads. A data consistency problem occurs if two or more threads attempt to write data to the same memory location. Threads must coordinate using synchronization mechanisms in order to avoid data consistency problems. A synchronization mechanism ensures that only one thread can execute a specific segment of code. There are many libraries and APIs for shared memory programming. The following are some examples.

Open Multi-Processing (OpenMP) \cite{openmp} is an API that has been designed to develop applications that are meant to be executed on shared memory parallel computers such as multi-core computers. OpenMP is supported by C, C++ and Fortran programming languages. The basic idea of OpenMP is that a master thread is responsible for the creation of slave threads that are allocated to processors to run in parallel. The creation of slave threads is called forking. It is the duty of the developer to specify parts of the code that can run in parallel using preprocessor directives. These directives cause the threads to be created before their execution. When the execution of the slave threads is finished, they join back to the master thread which continues the execution of the program. OpenMP can be used for both data and task parallelism.

Intel Threading Building Blocks (Intel TBB) \cite{reinders:2007} is a C++ parallel programming library. Using Intel TBB, the developer specifies the parallelism in the form of tasks, not threads. Such tasks are pieces of code that can be executed in parallel but, in contrast to threads, they are not explicitly assigned to hardware resources. For instance, on a multi-core processor, the library creates one thread per core and automatically maps the tasks onto the threads. Therefore, the developer focuses on specifying the parallelism (what can be executed in parallel) instead of handling the parallelism (how to map the parallelism). Intel TBB uses work stealing, i.e. it dynamically tries to balance the computation load among the available processors at runtime.

Shared memory programming can be done using low level multi-threading also. For instance by using POSIX threads (pthreads) or Windows threads. Such low-level approach gives the developer more flexibility and control over the threads, e.g. thread creation and mapping, compared to using libraries such as OpenMP or Intel TBB. Nonetheless, the latter are simpler to use. 

\subsubsection{Distributed Memory Programming}

Distributed memory programming is done using processes that are executed on different processors. The data needs to be partitioned and mapped to the processors with the corresponding tasks. Data is moved between processors if needed. An important challenge is to keep data exchange as low as possible in order to minimize the communication between the processors. Data consistency is not a concern in distributed programming, since each process only writes to the local memory. Nevertheless, the developer needs to implicitly specify the communication between the processors through message passing.  

The classical standard for distributed memory programming is the Message Passing Interface (MPI) \cite{mpi}. MPI is a standard for programming distributed memory parallel computers. It is supported by many programming languages and platforms. It defines a communication protocol for performing the message passing and provides communication and synchronization functionalities for collaborating processes that are allocated to different processors. It supports different kinds of communications such as point-to-point and collective communication. It is also possible to choose the topology of communication to be used.

For more on parallel programming, one can refer to the survey presented in \cite{diaz:2012}. It gives a very interesting review of the available parallel programming models and tools.

\subsection{\label{subsec:parsched}Parallel Scheduling}

Parallelization consists in partitioning a sequential program and allocating the different parts in order to be executed on multiple processors. In order to be parallelized, a program needs to be modeled in such a way to express the available parallelism. In general, a model of a program can be made by dividing the program into tasks of computations and defining dependence between them. 
If the number of the tasks is equal to the number of processors, the parallelization of the program can be achieved by allocating each task to a distinct processor. However, this is not the case in practice, i.e. there are much more tasks than processors. In this case multiple tasks are allocated to one processor and must be executed sequentially.  
Knowing the time needed to execute each task is also important to model the program. Depending on the application, other properties and constraints can be considered. Having a model of the program, the parallelization consists in defining a schedule for the different tasks, i.e. an allocation to a processor and a time for starting the execution of each task. Parallel computing has received much interest in the scheduling theory community and many algorithms and models have been proposed to solve the problem of application parallelization.   

Scheduling in the broad sense refers to the theory, algorithms and systems that deal with problems of sequencing and allocating tasks to resources. Scheduling theory has numerous areas of application like manufacturing, transportation, logistics, sports scheduling, project management, etc.% The objective of scheduling for parallel computing is to take full advantage of a parallel architecture for the execution of a parallel application . 
 A significant part of the research carried out in the scheduling theory field treats problems related to scheduling computational tasks on parallel computers. This kind of scheduling is known as parallel scheduling. We focus in this section on parallel scheduling from a computing point of view.

In a parallel scheduling problem, the resources are the processors (or cores of a multi-core processor) and the tasks are the computation functions of the application to be executed. Resources are traditionally referred to as computers, or sometimes machines, and tasks can be referred to as jobs. We use the terms processors, to refer to processing elements of a parallel computing system, and tasks to refer to the computational tasks of the application to be executed. A set of $n$ tasks is denoted $\mathcal{T} = \{\tau_1, \tau_2, \ldots, \tau_n\}$ and a set of $m$ processors is denoted $P = \{p_1, p_2, \ldots, p_m\}$. Scheduling consists in allocating tasks from $T$ to processors from $P$ with respect to predefined criteria, e.g. the minimization of the total execution time of all tasks. Scheduling implies also the definition of an execution order for the tasks that are allocated to the same processor by setting execution start times for the tasks. In general, each task has to be allocated to one and only one processor and a processor can execute at most one task at a time. Additional constraints can be considered depending on the problem.

In scheduling problems, processors can be classified based on their speed of execution \cite{davis:2011}:

\begin{itemize}
\item \textit{Heterogeneous}: The execution speed of a task depends on both the processor and the task. Not all tasks may be executed on all processors.
\item \textit{Homogeneous}: The processors are identical. The execution speed of a given task is the same on all processors.
\item \textit{Uniform}: The execution speed of a task depends only on the speed of the processor. A processor of speed 2 will execute all tasks at exactly twice the speed of a processor of speed 1.
\end{itemize}

A schedule is called preemptive if the execution of a task can be interrupted by another task of higher priority and resumed later. If a schedule is not preemptive, it is called non preemptive. Furthermore, scheduling algorithms can be classified into online and offline algorithms. Online scheduling algorithms are used when some information about the tasks is not known before the execution. The scheduling algorithm makes scheduling decisions online as the information becomes available. Offline scheduling algorithms can be used when the characteristics of the tasks, such as dependence between them and their execution times, are known before the execution. It is then possible to compute the schedule of the tasks offline.

Scheduling research has been active for over 60 years now and so many methods and algorithms have been proposed to solve different scheduling problems. Different performance measures can be considered such as the makespan objective, the total completion time objective, and the number of late tasks objective \cite{leung:2004}. The makepsan is the time needed by a computer to process the whole set of tasks. The general objective of parallel computing is to accelerate the execution of application which corresponds to minimizing the makespan.

\subsubsection{Task Dependence Graph}

A set of tasks $\mathcal{T}$ which express the parallelism of an application can be represented by a Directed Acyclic Graph (DAG) $G(V,A)$ called the task dependence graph. Each task $\tau_i \in \mathcal{T}$ is represented by a vertex $v_i \in V: 0 \leq i < n$ where $n$ is the number of tasks called, also, the size of graph $G(V,A)$. Dependence between tasks is represented by arcs $(v_i, v_j) \in A: 0 \leq i,j < n$. A vertex may have one or more incoming edges which connect it with its predecessors and one or more outgoing edges which connect it with its successors. A task cannot start its execution unless all its predecessors have finished their execution. Generally, dependence between two tasks is due to data transfer, i.e. one task is executed and produces data that another task needs to consume to start its execution. If a vertex has no predecessor it is called an entry or source vertex. A vertex that has no successor is called an exit or sink vertex. The vertices may be weighted by the execution times of the corresponding tasks. Figure \ref{fig:dagex} shows an example of a task dependence graph. In the remainder of the thesis, for the sake of simplicity we will use the term dependence graph instead of task dependence graph.

%A task dependence graph is a DAG denoted $G(V,A)$ where:
%
%\begin{itemize}
%\item $V$ is the set of vertices of the graph. The size of the graph $n$ is equal to the number of its vertices. Each vertex $v_i: 0 \leq i < n$ represents a task which is an atomic unit of computation, i.e. it cannot be allocated to several computing resources.
%\item $A$ is the set of arcs of the graph. A directed arc is denoted as a pair $(v_i,v_j)$ and describes a precedence constraint between $v_i$ and $v_j$, i.e. $v_i$ has to finish its execution before $v_j$ can start its execution. $v_i$ is called the \textit{tail} vertex and $v_j$ is called the \textit{head} vertex. 
%\end{itemize}

\begin{figure}[phbt]
\centering
\includestandalone{figures/dagex}
\caption{Example of a task dependence graph.}
\label{fig:dagex}
\end{figure} 

\subsubsection{Potential and Effective Parallelisms}

In industrial practice, we distinguish between the \textit{functional} and \textit{non functional} specifications. Functional specification consists in defining what has to be done. Mainly, the different functions of the application and the dependence between them are specified. Non functional specification consists in defining how the functions have to be performed. It provides a description of the hardware architecture, its different components and how they are interconnected. It specifies also allocation constraints if there are any and the timing parameters of the different functions, such as their execution times and periods.

Having both the functional and non functional specifications, the \textit{potential} and the \textit{effective} parallelisms can be deduced. The potential parallelism is related to the functional specification. It is defined by the functions that are not dependent as they can potentially be executed in parallel, e.g. $\tau_2$ and $\tau_3$ in Figure \ref{fig:dagex}. The effective parallelism is defined by the hardware architecture, i.e. how many processing elements (processors, cores, \ldots) are able to execute functions in parallel. If the effective parallelism is less or equal to the potential parallelism, the execution of the application is accelerated. If it is greater, the execution is accelerated also but, no matter how much the effective parallelism is increased, the speedup remains constant. This can be interpreted by Amdahl's law which describes how hardware parallelism limits the exhibition of software parallelism.


\subsubsection{List Scheduling}

Heuristics are usually used to solve parallel scheduling problems because these problems are NP-complete \cite{garey:2002} and using exact algorithms results in exponentially increasing execution times. In particular, list scheduling heuristics have been successfully used in the context of offline scheduling. All list scheduling heuristics are based on the same idea. Tasks that are ready to be scheduled are kept in a list. A task becomes ready to be scheduled once all its predecessors have been scheduled. The heuristic assigns priorities to the tasks in the list and selects the task with the highest priority to schedule it. This process is repeated untill all the tasks have been scheduled. The way the priorities of tasks are computed differs from one list scheduling heuristic to another. In the following, we review list scheduling heuristics that are proposed in the literature for makespan minimization.

A well-known algorithm to minimize the makespan of a dependence graph with no transitive arcs is Hu's algorithm \cite{hu:1961}. It assigns a level to each task in the dependence graph as follows: All tasks that have no immediate successor are at level one. Then, for each of the other tasks, the level is equal to one plus the maximum level of its immediate successors. Hu's algorithm proceeds repeatedly by allocating each time the ready task (whose all immediate predecessors have already been allocated) which has the highest level among all ready tasks to the first available processor. 

Coffman-Graham algorithm \cite{coffman:1972} performs the scheduling in two steps. First a task is labeled with a label which is a function of the labels of its immediate successors (the labeling algorithm is not detailed here). Tasks are then allocated following a highest label first policy. 

Papadimitriou and Yannakakis \cite{papadimitriou:1979} studied the problem of scheduling interval-ordered dependence graphs. In such a graph, two tasks are precedence-related if and only if they can be mapped to non-overlapping intervals on the real number line \cite{fishburn:1985}. A task is assigned a priority based on the number of its successors. A list of the tasks is constructed in a descending order of their priorities and then the tasks are allocated in this order. 

In \cite{adam:1974}, level-based algorithms for scheduling dependence graphs are presented. The proposed Highest Level First with Estimated Times algorithm labels the tasks of the dependence graph with levels where a level corresponds to the length of  the longest path from the task to a sink task. It, then, allocates the tasks in a highest-level first fashion. Therefore, the level of a task represents its priority. Highest Level First with No Estimated Times algorithm works similarly but with the assumption that all tasks have unit computation costs. In \cite{kasahara:1984} a similar algorithm is proposed with the improvement of breaking ties by selecting the task with the largest number of successors. 

In \cite{shirazi:1990}, two algorithms are proposed: First, the Heavy Node First algorithm which is based on a local analysis of the tasks at each level. In this algorithm, a level of a task corresponds to the longest path from a source task to this task. It allocates the heaviest task first. The second algorithm, Weighted Length (WL), considers a global view of the dependence graph by taking into account the relationships among the nodes at different levels. 

The authors of \cite{kruatrachue:1987} proposed the Insertion Scheduling Heuristic (ISH). The main idea of ISH is to fill the \textit{scheduling holes} which are the idle time slots that appear as the schedule is being constructed.

The Modified Critical Path (MCP) algorithm proposed in \cite{wu:1990} uses the measure of how late can a task be delayed without increasing the makespan of the schedule. The MCP algorithm assigns priorities to tasks in an ascending order of their latest start dates. 

The Earliest Start Time algorithm \cite{hwang:1989} computes at each step, for each task, the earliest start date and selects the task that has the smallest one to allocate it. 

The Dynamic Level Scheduling (DLS) algorithm \cite{sih:1993} assigns dynamic levels to tasks. The Dynamic Level (DL) of a task is equal to the difference between the \textit{b-level} (longest path from the corresponding task to a sink task) of the task and its earliest start date. At each step, the algorithm computes the dynamic levels for the ready tasks on all processors. The task-processor pair that gives the largest DL is selected for scheduling. 

In \cite{yang:1994}, Yang and Gerasoulis present the Dominant Sequence Clustering (DSC) algorithm that uses an attribute called the dominant sequence which is the critical path of the dependence graph.

A current trend in multiprocessor scheduling is to use meta-heuristics such as Genetic Algorithms (GA) \cite{hou:1994, wu:2004, omara:2010}.

\subsection{Parallel Real-time Scheduling}

Real-time scheduling concerns the scheduling of tasks in real-time systems. Real-time does not mean fast. Instead, it refers to systems that must be able to respond to external events within specified deadlines. Real-time systems are typically found in the form of embedded systems that control physical processes. They represent the cyber part in a CPS. In general, real-time systems are computing systems that are characterized by timing constraints in addition to the functional requirements. A part of this thesis deals with HiL simulation which can be qualified as a real-time system because the simulated part has to meet predefined deadlines in order to ensure correct results.
In order to implement real-time applications, first, \textit{real-time tasks} are defined by characterizing the functions obtained from the functional specification by a number of timing parameters. A real-time task denoted $\tau_i$ is characterized by the following parameters (see Figure \ref{fig:taskmodel}):
\begin{itemize}
\item Release time $r^k_i$: Typical real-time applications consist of a set of tasks that are executed repeatedly where each execution is called an occurrence. The time at which an occurrence becomes ready to be executed is called the activation or the release time. $r^k_i$ is the release time of the $k^{th}$ occurrence of the task $\tau_i$;
\item First release time: $r^0_i$, called also offset;
\item Start time $s^k_i$: The time at which the $k^{th}$ instance starts its execution $(s^k_i \geq r^k_i)$;
\item Execution time $C_i$: A real-time task has an execution time which cannot be considered to be fixed and may vary from one execution to another. Therefore, a real-time task is characterized by its Worst Case Execution Time (WCET);
\item Finishing time $f^k_i$: The time at which the $k^{th}$ occurrence finishes its execution;
\item Response time $R^k_i$: The duration between the release time and the finishing time of the $k^{th}$ occurrence: $R^k_i = f^k_i - r^k_i$;
\item Absolute deadline $d^k_i$: The time by which the $k^{th}$ occurrence must finish its execution;
\item Relative deadline $D_i$: Starting from the release time, the duration within which the task has to finish its execution;
\item Laxity $l^k_i(t)$: Difference between the absolute deadline and the time for which the task has been running: $l^k_i=d^k_i-(t+C_i(t))$.
\end{itemize}

In addition, real-time tasks are characterized by a parameter related to how consecutive occurrences of a task are activated. Three kinds of tasks can be distinguished:
\begin{itemize}
\item Periodic tasks: The occurrences of a given task are activated periodically with a known period. A periodic task is characterized by its period $T_i$;
\item Sporadic tasks: The occurrences of a task are activated such that the minimum time between two successive activations is known. A sporadic task is characterized by $T_i$, its minimum arrival time;
\item Aperiodic tasks: The minimum delay between two activations is not known.
\end{itemize} 

\begin{figure}[phbt]
\centering
\includestandalone{figures/taskmodel}
\caption{Parameters of a real-time task.}
\label{fig:taskmodel}
\end{figure} 

Real-time systems can be classified based on the impact of missing deadlines. Hard real-time systems are systems where all deadlines must be met. Violating this constraint leads to the failure of the system and may result in a great loss such as serious injuries, threatening human life, or damaging the surroundings. Soft real-time systems can tolerate some deadlines to be missed but the quality of the result degrades consequently. Firm real-time systems allow only a certain number of deadlines to be missed. We consider that HiL simulation falls within the category of firm real-time systems. In fact, in order to have correct HiL results, deadlines must be met. If a task misses its deadline, it produces invalid results and may cause the failure of the system but the consequences are not as catastrophic and harming as in the case of hard real-time systems.   

Many different real-time scheduling algorithms have been proposed in the literature but they are all based on the same idea; tasks are assigned priorities and then scheduled in an order following their priorities. We distinguish between fixed priorities which do not change during the execution and dynamic priorities which are computed by the scheduler during the execution. Also, as in other kinds of scheduling problems, real-time scheduling algorithms can be classified into offline/online and preemptive/non preemptive algorithms.

The main goal of scheduling in real-time systems is to satisfy the different timing constraints of the tasks, i.e. release times, periodic activations, deadlines, etc. Schedulability tests can be used to check whether the tasks can be scheduled using a given scheduling algorithm in such a way to satisfy all the requirements. A schedulability test verifies if the utilization or the density of the processor, defined below, when it executes the set of tasks under test, is within a least upper bound. For a set of $n$ independent periodic tasks, the utilization factor and density, when a preemptive scheduling algorithm is used, are respectively:

\begin{equation}
U = \sum_{i=1}^{n}\frac{C_i}{T_i}
\end{equation}

\begin{equation}
\Delta = \sum_{i=1}^{n}\frac{C_i}{D_i}
\end{equation}
The most known real-time scheduling algorithms are the following:

\begin{itemize}
\item Fixed priorities
\begin{itemize}
\item Rate Monotonic (RM) \cite{liu:1973}: Tasks are assigned priorities inversely proportional to their periods. A set of tasks $\tau_i \in \mathcal{T}: D_i = T_i$ is schedulable by RM if $U \leq n(2^{\frac{1}{n}}-1)$. 
\item Deadline Monotonic (DM) \cite{leung:1982}: Tasks are assigned priorities inversely proportional to their relative deadlines. A set of tasks $\tau_i \in \mathcal{T}: D_i \leq T_i$ is schedulable by DM if $\Delta \leq n(2^{\frac{1}{n}}-1)$. 
\end{itemize}
\item Dynamic priorities
\begin{itemize}
\item Earliest Deadline First (EDF) \cite{liu:1973}: Priorities of tasks are inversely proportional to their absolute deadlines. The priority of a task is fixed for one occurrence but may change from one occurrence to another. EDF can schedule a set of tasks $\tau_i \in \mathcal{T}: D_i = T_i$ iff: $U \leq 1$.
\item Least Laxity First (LLF) \cite{mok:1983}: Priorities of tasks are inversely proportional to their laxities. The priority may change for the same occurrence and from one occurrence to another. The schedulability test is the same as for EDF.
\end{itemize}
\end{itemize}
 For multiprocessor real-time scheduling, there exist two principal approaches \cite{andersson:2000}:

\begin{itemize}
\item Global scheduling: Each task can be scheduled on any processor. the scheduler is responsible for migrating the tasks between the processors.
\item Partitioned scheduling: The tasks are partitioned into groups, each of which is allocated to one processor. Each processor has a single-processor scheduler. 
\end{itemize}
Global multiprocessor scheduling has significant overhead due to the migration cost. This is the reason why partitioned scheduling is usually used in hard real-time systems. Partitioning and allocating a set of tasks is equivalent to the \textit{Bin Packing} problem which is NP-hard and heuristics are therefore used. 

Assuming the tasks are sorted in a list and that processors are organized in a certain order, the most known heuristics that can be used to allocate a set of tasks to multiple processors are:

\begin{itemize}
\item Next Fit (NF): A task is tested on the available cores starting from the core the heuristic last allocated a task to. The task is allocated to the first found core that can schedule it. A task is schedulable on a given core if by allocating it to this core the condition $(U\leq1)$ is valid where $U$ is the utilization of the core.
\item First Fit (FF): Similar to NF but the search of the core that can schedule the task always starts from the first one.
\item Best Fit (BF): Test the task on all cores and allocate it to the one that gives the minimum of $U$.
\item Worst Fit (WF): Test the task on all cores and allocate it to the core that gives the maximum of $U$.
\end{itemize}
  
\subsection{Parallel Execution}

It is important to understand how the previously presented concepts of parallel computing are related. These concepts are involved in parallelization which refers to the process that takes as input a sequential code and achieves a parallel execution of the program. The first step of parallelization consists in detecting the potential parallelism of the program. Depending on the class of parallelism (e.g. task or data), a model, such as a dependence graph, is used in order to represent this potential parallelism. The targeted parallel architecture has to be modeled as well in order to accomplish the parallelism adaptation. Given the models of the potential parallelism and the effective parallelism, a schedule has to be found. In other words, the different parts of the program are allocated to the different components of the parallel architecture and their execution is ordered. Finally, based on the computed schedule, a parallel code is generated to be executed on the parallel architecture.  

\subsubsection{The AAA Methodology and SynDEx Software}

The goal of the Algorithm-Architecture-Adequation (AAA) methodology \cite{sorel:1996} is to find out the best implementation of an algorithm specifying the functions that the application has to perform onto a multicomponent architecture, while satisfying real-time and embedding constraints. The AAA methodology is based on graph models to exhibit both the potential parallelism of the application algorithm and the available parallelism of the hardware architecture.  Adequation means an efficient implementation. The implementation consists in distributing and scheduling the algorithm graph onto the multicomponent graph while satisfying real-time constraints. This is formalized in terms of graph transformations. Heuristics based on distributed real-time scheduling analyses taking into account timing characteristics attached to tasks (period, worst case execution time of computations and of inter-component communications), are used to automatically explore the possible implementations of a given application onto a given multicomponent hardware that satisfy real-time constraints, and to optimize the reaction time as well as resource allocation. The result of graph transformations is an optimized Synchronized Distributed Executive (SynDEx) dedicated to the application, automatically built from a library of architecture dependent executive primitives composing each executive kernel. (Figure \ref{fig:aaa}).

\begin{figure}[phbt]
\centering
\includestandalone{figures/aaa}
\caption{The Algorithm-Architecture-Adequation methodology.}
\label{fig:aaa}
\end{figure} 

\section{Parallel Execution of Co-simulation}

The more accurate is a simulation of a system, the more reliable is the assessment of its behavior. The numerical accuracy can be improved in different ways, for instance, by choosing a small integration step size. However, this means that more computations are performed and thus the computation load becomes large, decreasing the simulation performance. An important challenge faced by the developers and the users of simulation tools is to achieve a good simulation performance while maintaining an acceptable simulation accuracy. 

The performance of a simulation can be significantly improved through parallel execution. In this scope, different approaches for the parallelization of simulation have been proposed in the literature. In this section we briefly review some of the approaches for the parallelization of simulation that are found in the literature. We present also some of the available simulation tools that support parallel simulation.

\subsection{\label{subsec:parsimaprr}Approaches}

In order to achieve simulation acceleration through parallel execution, different approaches are possible. Parallelization approaches can be classified into three categories based on the level at which the parallelization is introduced.

\subsubsection{Parallelization across the method}
In this category, we find approaches that seek to parallelize the integration method. For instance, a multi-stage solver requires several computations within one integration step and it is possible to perform such computations in parallel. Such approach is studied in \cite{iserles:1990} by proposing a theoretical framework for the parallelization of Runge-Kutta methods. Another approach consists in parallelizing operations on vectors for ODE resolution like in the PVODE solver \cite{byrne:1999} implemented using MPI. 

In \cite{elmqvist:2015}, the authors propose a method for parallelization of modelica programs on CUDA-enabled GPUs. The proposed method relies on marking the functions to be executed on the GPU by identifying patterns that are GPU suitable such as loops. These functions are then automatically translated into GPU code. In \cite{Gebremedhin2012}, ParModelica, an algorithmic extension of Modelica is proposed. This extension is based on OpenCL and allows stating the parallelism using special declarations in the code. An approach for automatic parallelization of equations on many-core platforms is proposed in \cite{elmqvist:2014}. This approach organizes the equations into a set of layers containing, each, a number of sections that can be executed in parallel and computes an offline schedule for their execution. In \cite{clauberg:2012} an approach for the parallelization of multi-body simulation (simulation of systems composed of rigid and flexible bodies) on shared memory multiprocessors is proposed. This approach uses math-kernel libraries and OpenMP to parallelize matrix operations.

\subsubsection{Parallelization across the time}

A simulation can be parallelized across the time steps. Examples of such approach are the Parareal algorithm \cite{lions:2001}, the Parallel Implicit Time-Integrator (PITA) \cite{farhat:2003}, and the Parallel Full Approximation Scheme in Space and Time (PFASST) \cite{emmett:2012}. These methods divide the time domain into a two-level grid. A solution is evaluated in parallel over a fine time grid to improve a solution obtained sequentially over a coarse time grid.
\subsubsection{Parallelization across the system}

Finally, a simulation can be parallelized across the system, i.e. the equations used in the simulation are solved in parallel. A well known approach that parallelizes across the system is Waveform Relaxation (WR) \cite{lelarasmee:1982}, initially introduced for the simulation of large scale integrated circuits. The WR method breaks down the system into coupled subsystems of equations and computes the waveform, i.e. the solution, of each subsystem over a given time interval while fixing the waveforms of the other subsystems. The parallelization is made possible by computing the waveforms of several subsystems in parallel. The term waveform is used as the method was originally used to solve differential equations describing electrical circuits where signals are referred to as waveforms. 

Transmission Line Modeling (TLM) \cite{hui:1990} is a method that allows the decoupling and the parallelization of models by representing them using transmission line graphs such that decoupling points are chosen where variables change slowly because the models are considered to be connected by constants at these points. The approaches presented in \cite{sjolund:2010,braun:2012} are based on the TLM method. 

An automatic parallelization approach based on dependence graph scheduling is presented in \cite{aronsson:2006}. For this, the simulation code is analyzed at the expression level to build the dependence graph. A clustering algorithm is also proposed in this work to merge tasks. Finally an offline scheduling heuristic is applied on the dependence graph.

Co-simulation is naturally adapted to parallelization across the system. In fact, as shown in \cite{Benkhaled_A_2012_ECOSM}, splitting a model into several FMUs, by isolating discontinuities, may reduce the simulation time, even in the case of a sequential execution. In \cite{benkhaled:2014}, the Refined CO-SIMulation (RCOSIM) approach is presented. It consists in using each FMU information on input/output causality to build a graph, with an increased granularity and then exploiting the potential parallelism by using a heuristic to build an offline multi-core schedule in order to accelerate the execution.

The parallelization approach of the DACCOSIM tool is presented in \cite{galtie:2015}. Thanks to a graphical user interface, different FMUs of a co-simulation can be allocated to different multi-core computing nodes manually. If two dependent FMUs are allocated to different nodes, TCP connection is used for communication. Otherwise, interprocess communication is used. Each FMU is executed on its own thread on a distinct core. In addition, DACOSSIM is able to perform input extrapolation. This work has been later extended in \cite{galtier:2017_experimenting}. The extension allows encapsulating DACCOSIM and the FMUs it controls in what is called a \textit{Matryoshka} FMU. This allows to import DACCOSIM into other FMI compliant tools.

%The authors of \cite{lacoursiere:2017} propose a client-server architecture for distributed FMI co-simulation. Multiple servers are involved, running, each, a single FMU and a client plays the role of the orchestrator of the co-simulation.

In \cite{lundvall:2007}, the authors propose a solution that combines two paralleization approaches: paralleization across the time and parallelization across the system. In particular, the proposed solution allows performing several stages of the Runge-Kutta solver in parallel within a single step. In addition, paralleization across the system is performed by parallelizing the computations involved in evaluating the equations of the system. A dependence graph of these computations is built and then scheduled on a multi-core processor. 

\subsection{Tools}

More and more simulation tools are now endowed with parallel execution capabilities. However, it should be noted that some of these tools adopt parallelization approaches that do not target the numerical part of the simulation. For instance, the Parallel Computing Toolbox in MATLAB allows launching multiple Simulink simulations of the same model in parallel on a desktop multi-core computer or a cluster. These are separate independent simulations of the same model. This feature allows running multiple simulations under different configurations and conditions at the same time. It does not correspond to the focus of this thesis, i.e. the parallelization of the numerical computations of a simulation. Also, Simulink provides an execution mode known as Rapid Accelerator Mode which consists in creating a standalone executable of the model and the solver. Simulink runs in one process and this standalone executable runs in another process on a multi-core processor. Again, although this approach may improve the performance of the simulation, it does not lie within the scope of the thesis.

The Dymola tool enables automatic parallelization of equation resolution. The parallelization approach of Dymola is detailed in \cite{elmqvist:2014}. LMS Imagine.Lab Amesim allows launching multiple simulations in parallel, for example to run a model with different parameters. It has also the capability of partitioning models and executing them on multi-core processors. The TLM method, presented above, is integrated in the Hopsan tool. Finally, MBSim parallelizes matrix and vector operations as described in \cite{clauberg:2012}. The co-simulation software xMOD is able to execute FMI co-simulations in parallel on multi-core architectures. It uses the RCOSIM approach \cite{benkhaled:2014} presented in Section \ref{subsec:parsimaprr}.  