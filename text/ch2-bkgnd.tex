\chapter{\label{ch:2-bkgnd}Background}

\minitoc

This chapter describes fundamental concepts and gives literature review about research topics that are involved in this thesis. Topics covered include modeling and simulation, co-simualtion, parallel computing, scheduling in the context of parallel computing, and parallelization approaches related to (co-)simulation. 

\section{Modeling and Simulation}

The design of complex systems impose the study of their behavior before building them with the objective of allowing preliminary evaluation, tuning and possibly redesign of the solution. Simulation has proven successful in responding to this need and became an indisputable step in the design process of complex systems. Simulation is an effective way for cost reduction since it allows correcting design errors before building the system. Simulation is performed by providing models which describe the system and then bringing these models to life by running them in order to imitate, on a computer, the behavior of the simulated system over time.   

\subsection{Systems}

Before detailing the concepts and methods of modeling and simulation of systems, it is important to understand what is meant by a system. A system is defined as a set of interacting parts which form a complex whole and operate towards a common goal. 

In order to have clearer understanding, the notion of a system should be conceived in the scope of the context that it is used in. In engineering domains, in addition to the definition given above, a system can be seen as an entity which consumes inputs from the environment and produces outputs to the environment, and is characterized by an internal state. The state of the system is affected by the inputs that it consumes, and, in turn, affects the produced outputs. Figure \ref{fig:system} illustrates this view as usually found in block diagrams where $u$ represents the input of the system, $y$ the output, and $x$ the internal state.

\begin{figure}[phbt]
\centering
\includestandalone{figures/system}
\caption{A block diagram representation of a system.}
\label{fig:system}
\end{figure}

A kind of systems that falls within the scope of this thesis is known as Cyber-Physical Systems (CPS) \cite{lee:2016}. CPS consist of a combination of tightly or loosely interacting computational elements and physical processes. The computational elements are called embedded systems or controllers and are used to control the physical processes. They are interfaced with the physical processes through sensors and actuators. The aim of the controller is to bring the physical process to a desired state by sending digital control data. If the physical process does not in turn send back data to the controller, the system is referred to as \textit{open loop control}. Alternatively, the controller's behavior is possibly adapted to the change in the state of the physical process which sends feedback data. The term \textit{closed loop control} is used to refer to such interaction between the controller and the physical process. Basically, an error, which is the divergence between the aimed behavior, called reference, and the actual behavior of the physical process is measured and corrected. Figure \ref{fig:feedb} shows a basic example of a CPS with feedback control. It is common that CPS contain multiple feedback loops and involve simple or sophisticated networks that are used for the communication between the different parts of the CPS. A Digital-to-Analog converter is used to convert the data produced by a controller to be consumed by a physical process. Conversely, an Analog-to-Digital Converter (ADC) is used to convert the data produced by a physical process to be consumed by a controller. 

\begin{figure}[phbt]
\centering
\includestandalone{figures/feedbackloop}
\caption{Feedback control of a physical process.}
\label{fig:feedb}
\end{figure}  

Areas where CPS can be found are as important as automotive, aerospace, manufacturing, transportation and many others. The diversity of the involved disciplines makes the process of building CPS challenging, costly and time consuming.

\subsection{Modeling}

Modeling a system consists in creating a mathematical abstraction of its behavior. The first step is to choose a modeling formalism. This choice depends on the properties of the system, the objective of the simulation, and the aimed level of detail in the simulation. For instance, models can be built using continuous-time variables to represent continuous dynamics of a physical process. Such mathematical models consist of a set of differential equations which describe the continuously changing physical quantities of a process such as electrical circuits, fluid dynamics, chemical reactions, etc. Other systems feature a behavior which evolves between a finite set of states. These systems can be modeled using formalisms such as DEVS (Discrete Event System Specification) \cite{zeigler:2000}, Statecharts \cite{harel:1987}, and Petri nets \cite{petri:1962}. Finally, hybrid modeling allows the modeling of systems with both continuous variables and discrete states. In other words, the system jumps between discrete states and while it is in a certain state, it features a continuous behavior, {\em i.e.} its quantities change continuously. 

In this thesis, we focus on the modeling of dynamical systems using differential equations. A differential equation expresses a variable as a function of its derivatives. In the modeling of dynamical systems, the variables are the physical quantities and the derivatives express their rates of change. A differential equation is called Ordinary Differential Equation, abbreviated ODE, if it involves ordinary derivatives of the variables with respect to an independent variable (usually the time in the modeling of dynamical systems). The ordinary derivative consists in computing the derivative of the function allowing all variables to vary. The term ordinary is used in contrast with the term Partial Differential Equation presented below. Equation \ref{eq:ode} is an ODE where $x$ is the vector of the variables of interest called the state variables, $\dot{x} = \frac{dx}{dt}$ is the vector of the time derivatives of the state variables, $t$ is the time (the independent parameter), and $f$ is a given function.

\begin{equation}
 0 = f(\dot{x},x,t) \equiv f(\frac{dx}{dt},x,t)
\label{eq:ode}
\end{equation}

A differential equation is called Partial Differential Equation, abbreviated PDE if it involves unknown functions and their partial derivatives. A partial derivative of a function is its derivative with respect to one variable while holding the other variables constant. Equation \ref{eq:pde} shows such PDE where $x_1,x_2,\dots, x_n$ are the parameters, $y=y(x_1,x_2,\dots, x_n)$ is the unknown function, $\frac{\partial y}{\partial x_i}, 1 \leq i \leq n$ are the partial  derivatives of $y$, and $f$ is a given function.

\begin{equation}
0 = f\biggl(x_1,x_2,\dots, x_n,y,\frac{\partial y}{\partial x_1},\frac{\partial y}{\partial x_2},\dots,\frac{\partial y}{\partial x_n}\biggl)
\label{eq:pde}
\end{equation} 

A Differential Algebraic Equation, abbreviated DAE, is a system of equations which involves algebraic equations in addition to differential equations. A DAE can be written in the form shown in equation \ref{eq:dae} where $f$ represents differential equations involving derivatives of variables and $g$ represents algebraic equations which do not contain derivatives.

\begin{equation}
\begin{aligned}
&0 = f(\dot{x},x,t) \equiv f(\frac{dx}{dt},x,t) \\
&0 = g(x,t)
\end{aligned}
\label{eq:dae}
\end{equation}
  
In this thesis, we are particularly interested in modeling dynamical systems using ODEs. Typically, such systems are hybrid dynamic systems modeled using hybrid ODEs. These systems exhibit continuous behavior interspersed with jumps triggered by some events. There are two kinds of events: Events which occur at a particular instant in time are called \textit{time events}. The other kind of events, called state events or zero-crossing, arise as a result of the value of a state variable crossing a specific threshold. Time events are easier to handle than state events since they occur at known instants in time. A classic example of such hybrid dynamic systems is the bouncing ball model where a ball is dropped from a certain height above the ground. The ball falls with a velocity subject to gravity and bounces when it hits the surface. Equation \ref{eq:bb} gives a hybrid system of equations which describes the behavior of the bouncing ball where $x$ is the position of the ball (height), $v$ its velocity, $g$ the gravity constant, and $\gamma$ the coefficient of restitution. The first and second time derivatives of $x$, $\dot{x} = \frac{dx}{dt}$ and $\ddot{x} = \frac{d^2x}{dt^2}$ represent the velocity and the acceleration of the ball respectively. 

\begin{equation}
\begin{aligned}
&\dot{x} = v\\
&\ddot{x} = -g\ \text{if}\ x > 0\\
&\dot{x} := -\gamma \dot{x}\ \text{if}\ x = 0 
\end{aligned}
\label{eq:bb}
\end{equation}  

The bouncing ball model exhibits a continuous behavior when $x > 0$ and discontinuities occur at bounces, i.e. when $x = 0$, where the velocity of the ball is inverted and scaled down by a factor equal to $\gamma$. In other words, the motion of the ball changes from downward to upward. This hybrid dynamic system can be modeled using a hybrid automaton as shown in Figure \ref{fig:bbautomaton}.

\begin{figure}[phbt]
\centering
\includestandalone{figures/bbautomaton}
\caption{Hybrid automaton of the bouncing ball system.}
\label{fig:bbautomaton}
\end{figure}

The discrete dynamics found in hybrid dynamic systems should be distinguished from the discrete nature of the controllers. The controllers are digital systems, hence, discrete systems. Control laws, i.e. the algorithms of control can be modeled in the continuous domain. However, since these laws are intended to be implemented on computers, a conversion from continuous to discrete is needed in order to implement them as controller software. When simulated (see next section) with the physical process, a control law that is modeled in the continuous domain is richer in terms of the information it gives about the controller behavior than its discrete counterpart. Also, continuous control laws allow better optimization of specific criteria that are of interest. The discrete control laws obtained through discretization of the continuous control laws are simulated with the physical processes in order to assess the effects of the discretization and, finally, implement the control software.

\subsection{Simulation}

Given a model of the system under study, the simulation consists in running this model in order to produce and plot, on a computer, data consisting in time varying values of the quantities of interest. These data are used in order to assess different aspects about the functioning of the system. Technically speaking, running a model which consists of a set of ODEs means solving these equations. In practice, it is not possible to find the solution of such equations analytically which imposes the use of numerical methods to solve them. Such numerical methods, called solvers, are based on the principle of discretization of the time $t$. This means that the values of the state variables $x(t)$ of an ODE in the form of equation \ref{eq:ode} evolve between discrete points of time, called \textit{time steps}, $(t_k, t_{k+1}, \ldots)$ instead of an evolution in continuous time $t \in \mathbb{R}^+$. The distance between two time steps is called the \textit{integration step size}. The smaller is the integration step size, the more accurate is the numerical resolution of the equations, i.e. the closer it is to the exact solution. However, reducing the integration step size requires more computations and thus slows down the execution of the solver. A tradeoff has to be made according to the desired quality and computation speed.

The discretized time can be written as: $t_k = k \times h$ where $h$ is the integration step size and $k \in \mathbb{N}$. The solver computes a sequence: $x_{k+1} = F(x_k,t_k)$ where $x_k$ is the value of the variable $x$ at $t_k$, the $k^{th}$ time step. $F$ is the solver or the integration function. Starting from the initial time $t_0$ and having the initial condition $x_0$, which is the value of $x$ at time $t_0$, the numerical resolution consists in computing approximate values of the quantity $x$ repeatedly with respect to the discretized time. The time step $h$ has to be chosen in such a way that the dynamics of the simulated system are well captured. When the system exhibits dynamics heterogeneity, e.g. fast transients and slow evolutions of the state variables, a fixed time step becomes less efficient. It is therefore  more efficient to use a variable time step. A solver with variable step controls the step size using a feedback loop on the error. The step size is adapted according to an estimation of the error. 

Solvers are characterized by a number of properties (e.g. order, explicit/implicit, fixed/variable integration step size, convergence, speed, \ldots) which should be taken into consideration when choosing a solver for a specific problem. %Overall, it is always desirable to choose a solver that is reliable, robust and fast.

As an example, the simulation of the bouncing ball model represented in Figure \ref{fig:bbautomaton} produces the plots shown in Figure \ref{fig:bbsim}. The time-varying position and velocity of the ball as it alternates between downward and upward movements are shown in Figure \ref{fig:bbpos} and Figure \ref{fig:bbve} respectively.

\begin{figure}[phtb]
\centering
\begin{subfigure}{\textwidth}
  \centering
  \includestandalone{figures/bbposition}
  \caption{Position}
  \label{fig:bbpos}
\end{subfigure}

\begin{subfigure}{\textwidth}
  \centering
  \includestandalone{figures/bbvelocity}
  \caption{Velocity}
  \label{fig:bbve}
\end{subfigure}
\caption{Trajectories obtained from the simulation of the bouncing ball model}
\label{fig:bbsim}
\end{figure}

Quantized State System (QSS) methods \cite{kofman:2001} offer an alternative to modeling an simulation methods based on time-discretization. Their principle is based on discretizing the state and considering the time as continuous. The resolution consists in solving for the time when the state changes by a quantum. These methods are out of the scope of this thesis. %This is because a part of this thesis targets real-time co-simulation which requires the time base to be known. Since QSS methods consider the time as an unknown continuous variable, they are not suitable for real-time co-simulation.  

\subsection{Co-simulation}

Complex systems may involve heterogeneous interacting parts. For instance, In a CPS, the controlled physical process constitutes a multi-physics system and is modeled in the continuous-time domain using (hybrid) Ordinary Differential Equations (ODEs). On the other hand, because they are implemented on embedded computers, numerical laws that control the physical process are modeled in the discrete-time domain. For such systems, it becomes necessary to do the modeling at the subsystem level, sometimes without a detailed view about the other subsystems. Models are then coupled together in order to perform simulation at the system level, known as co-simulation. In co-simulation, the different models are simulated in a black-box fashion and an orchestration of their interactions has to be ensured. The interactions between the involved models consist in data exchange.

Co-simulation is an alternative approach to monolithic simulation where a complex system is modeled as a whole using differential equations and simulated by numerically solving these equations. Co-simulation has a number of advantages over the monolithic approach. It allows modeling each part of the system using the most appropriate modeling tool instead of using a single one. Also, it allows a better intervention of the experts of different fields at the subsystem level. Furthermore, co-simulation facilitates the upgrade, the reuse, and the exchange of models. 

In co-simulation of models based on ODEs, the equations of each model are integrated using a solver separately. 
Models exchange data by updating their inputs and outputs at fixed points in time called \textit{communication steps}. The duration between two communication steps is referred to as \textit{communication step size} and denoted $H$. The communication step size associated with a model is a multiple of the integration step size of the model and defines the rate of communication (data exchange) of this model. It does not make any sense to use a communication step size that is smaller than the integration step size because communication should only be performed at points corresponding to integration steps. Thus, the communication step size should be at least equal to the integration step size. Using a communication step size that is a multiple of the integration step size is interesting when the inputs or the outputs of the model don't need to be updated at every integration step. For instance, if at one out of two integration steps, the model consumes new input values, its communication step size can be set to two times its integration step size. Therefore, the equations of the model are computed at every integration step, and its inputs and outputs are updated at every communication step. 
Figure \ref{fig:cosim} shows the evolution of time and data exchange between two models A and B. In this example, the equations of model A are solved using a fixed step size $h_A$ whereas the equation of model B are solved using a variable step step $h_B$. The communication step size $H $ is considerably larger than both integrations step sizes, allowing fast progress of the integration of the equations by restricting the data exchange to occur at communications steps only. Between communications steps, each model considers that the values of data produced by the other models are held constant. Another alternative is to estimate these values by employing extrapolation techniques.

\begin{figure}[phbt]
\centering
\includestandalone{figures/cosim}
\caption{Time evolution and data exchange between two models during co-simulation.}
\label{fig:cosim}
\end{figure}

For larger co-simulations involving more models, different communication step sizes may be associated with different models. In this case, we talk about multi-rate co-simulation.

In this thesis, we are interested, in particular, in co-simulations that are compliant with The Functional Mock-up Interface (FMI) standard \cite{fmi:2014}, presented hereafter. There exist other standards which target the coupling of simulators, e.g. the High-Level Architecture (HLA) \cite{ieee1516:2012}. The HLA is an IEEE standard developed by the U.S. Modeling and Simulation Coordination Office (M\&S CO)\footnote{www.msco.mil}. We are interested in the FMI standard because it is adopted by many modeling and simulation tools and is becoming the state of the art standard for co-simulation, thanks to the different possibilities of simulators and models coupling that it offers.

In the context of CPS which contain embedded systems controlling physical processes, different kinds of co-simulation, presented hereafter, can be performed depending on the stage of the controller design.

\subsubsection{Model-in-the-Loop}

At an early stage of the controller design, Model-in-the-Loop (MiL) co-simulation is performed. In MiL, the model of the controller is included with the model of the controlled physical process in a co-simulation in order used to test and validate the functioning scenarios of the controller. By using a system model, MiL aids in the design of control algorithms and also the investigation of design concepts. Once the functions of the control algorithm are specified, the controller software can be implemented.

\subsubsection{Software-in-the-Loop}

In the next stage, the controller software can be implemented to perform Software-in-the-Loop (SiL) co-simulation. The controller software code can be generated from the controller model. It is then integrated with the simulated models and executed on the computer that runs the simulation. SiL is an inexpensive approach to perform realistic tests of the controller’s performance without the need for using a special hardware. It is common to move back and forth between the MiL and the SiL stages to make necessary rectifications if design flaws are detected.

\subsubsection{Hardware-in-the-Loop}

After the verification of the controller software, the next stage consists in performing Hardware-in-the-Loop (HiL) co-simulation. In HiL, the controller software is implemented on the real hardware (e.g. Electronic Control Unit) which is connected to the computer that runs the simulation of the physical process. HiL must run in real-time in order to imitate the real interactions between the controller and the physical process. If any problems are detected, one can go back to SiL or MiL stage to make necessary corrections. Lamberg and W{\"a}ltermann enumerate the following advantages of HiL simulation \cite{lamberg:2000}:

\begin{itemize}

\item The controller algorithm can be tested in an early stage of the development process, allowing early potential corrections and tuning.

\item HiL is an efficient alternative for expensive field trials, experiments in borderline zones and hazardous situations.

\item Parameters can be tuned in order to perform tests under unusual conditions, e.g. extreme weather conditions. 

\item Failures that could lead to catastrophic damages in the real system, can be tested and corrected systematically.  

\item If needed, the tests can be reproduced repeatedly and automatically with high precision.

\end{itemize}

Figure \ref{fig:mbd} gives a view of the different types of co-simulation performed as part of the process of controller design.

\begin{figure}[phbt]
\centering
\includestandalone{figures/mbd}
\caption{Different types of co-simulation involved in the process of controller design.}
\label{fig:mbd}
\end{figure}

Coupling models and performing co-simulation presents many technical challenges. Some attempts have been made to establish methods that allow easy coupling of models and running co-simulations. In the following, we present a prominent industrial standard that was developed for model exchange and co-simulation.  

\subsubsection{The Functional Mock-up Interface Standard}

The Functional Mock-up Interface (FMI) is a tool-independent and open standard designed in the context of the European ITEA MODELISAR project and is currently developed and maintained by the Modelica Association\footnote{www.modelica.org/association/} which promotes the Modelica language (\ref{lngtoolsMS}). FMI standard was developed in order to facilitate the co-simulation of dynamical systems, such as CPS. It provides specifications in order to enable the exchange and the co-simulation of heterogeneous dynamical models that may be developed by different tools. A modeling tool that supports FMI can export a model as a Functional Mock-up Unit (FMU) which can be used in co-simulation environments. FMI defines interfaces for the involved models to allow their co-simulation.

%\begin{figure}[h]
%\centering
%\captionsetup{justification=centering}
%\includegraphics{figures/fmifigure}
%\caption{Vision on how FMI can be used in the automotive domain\footnotemark.} 
%\label{fig:fmifigure}
%\end{figure} 


An FMU is a package that encapsulates different files:

\begin{itemize}
\item An XML file that contains among other data the definition of the different variables of the models and the description of the dataflow between these variables. 
\item Model functions: Standardized C-functions that are used to create instances of the FMU and run them. The functions can be provided as platform dependent binaries (e.g. DLL files) or as C source code.
\item Documentation: Optional files that contain documentation about the model.
\end{itemize}

The FMI standard is organized in two parts:
\begin{itemize}
\item FMI for Model Exchange:
This specification provides interfaces and defines how model equations should be encapsulated in components. It allows solving each model independently using custom solvers. Accessing and computing the equations is done through standardized function calls. Figure \ref{fig:fmimdlexg} illustrates the principle of FMI for Model Exchange.

\begin{figure}[phbt]
\centering
\includestandalone{figures/fmimdlexg}
\caption{FMI for Model Exchange.}
\label{fig:fmimdlexg}
\end{figure}

\item FMI for Co-Simulation:
This specification defines interfaces between a master algorithm and slave models. It is intended to couple different simulators (models with their solvers) in a co-simulation environment. Figure \ref{fig:fmicosim} illustrates the principle of FMI for Model Exchange.

\begin{figure}[phbt]
\centering
\includestandalone{figures/fmicosim}
\caption{FMI for Model Co-Simulation.}
\label{fig:fmicosim}
\end{figure} 
\end{itemize}

In the context of FMI, we talk of model export and import. Model export means that a model is developed in one tool and then shipped as an FMU. Model import refers to using an FMU in a co-simulation environment different than the tool that was used to develop the FMU. In Figure \ref{fig:fmimdlexg} and Figure \ref{fig:fmicosim}, the different FMUs are imported into and executed within the co-simulation environment.

%Figure shows the state machine of the supported calling sequences from a master algorithm to a slave.

%\begin{figure}[h]
%\centering
%\captionsetup{justification=centering}
%\includegraphics[scale=0.6]{figures/callingsequence}
%\caption{Calling sequence of Co-Simulation C functions in form of an UML 2.0 state machine} 
%\label{fig:callingsequence}
%\end{figure}  

%The High Level Architecture (HLA) \cite{} is another standard for distributed simulation.
 

\subsection{Co-simulation under Real-time Constraints}

In the design process of complex systems, it is often necessary to test the behavior of the system or a part of the system as it would be produced by the real system. Therefore, the simulation is executed with real-time constraints such that the progress of the simulation time matches the real-time. For example, if temperature takes three minutes to reach $25$°, the simulation has to take three minutes as well. In the same way, a co-simulation under real-time constraints has to be executed such that the simulated time is advanced at the same speed as real-time.

A typical application of real-time co-simulation is HiL. The key advantage of real-time co-simulation is that it allows testing the controller under real-like conditions even if the physical process is not available. Many HiL solutions are developed in such a way to run the simulated part on special dedicated hardware that provides an execution fast enough to ensure real-time constraints. Other solutions tend to enable real-time co-simulation using general purpose computers equipped with Real-Time Operations Systems (RTOS).

Roughly speaking, the difference between real-time simulation and non real-time simulation is related to the notion of results validity. For non real-time simulation, one seeks to obtain results as soon as possible. The validity of the results depends only on their numerical accuracy. For real-time simulation, the validity of results depends on their numerical accuracy but also on their availability time, i.e. they have to be available within specific time \textit{deadlines}. If such deadlines are missed, the results are considered invalid even if their values are correct from a numerical standpoint.

Figure \ref{fig:rtcosim} illustrates the time evolution of a real-time simulation in comparison to accelerated non real-time simulation. For the former, during the resolution of the differential equations, the value of each variable $x$ is computed at every time step. The computation of $x_{n+1}$, the value of $x$ at time step $t_{n+1}$, cannot start before the value $x_n$ is computed as the computation of $x_{n+1}$ depends on the value of $x_n$. If the time required to compute the value of $x_{n+1}$ exceeds the step size, the real-time simulation constraints are violated which makes the simulation invalid. This is known as an \textit{overrun}. In the field of real-time systems, we talk also about \textit{deadline miss}. In the context of real-time simulation, the deadline of a variable computation is the time step by which the value of the variable has to be provided, e.g. time step $t_n$ for the computation of $X_n$.

Note that a real-time co-simulation is executed repeatedly. The execution is driven by real-time periods related to data exchange between the simulated part and the real part, e.g. the controller. This period can be different (usually greater) than the integration step-size of the co-simulation. In this case, not all computations are required to meet their deadlines. Instead, we seek "rendezvous" points where time-steps and real-time periods match. Only the computations whose deadlines corresponds to these points must not overrun. Hence, a co-simulation can be guaranteed to satisfy real-time requirements even if the rest of the computations miss their deadlines.   

\begin{figure}[phbt]
\centering
\includestandalone{figures/rtcosim}
\caption{Comparison of accelerated co-simulation and real-time co-simulation.}
\label{fig:rtcosim}
\end{figure} 

\subsection{\label{lngtoolsMS}Languages and Tools for Modeling and Simulation}

Building models of systems can be done manually and then transformed into software using general purpose programming languages such as C. However, this approach is not efficient in practice, especially when the modeled system is complex and changes may be required in the model. Many tools and languages for modeling and simulation have been developed in order to facilitate and make the modeling and simulation more efficient. Such tools allow the user to specify an equation-based model in a straightforward manner and come with built-in solvers. Below, we present a non exhaustive list of tools and languages for modeling and simulation.

%\begin{figure}[h]
%\centering
%\captionsetup{justification=centering}
%\includegraphics[scale=0.5]{figures/mipsxmod}
%\caption{Example of co-simulation models in xMOD.} 
%\label{fig:mips}
%\end{figure} 

\subsubsection{MATLAB Simulink}
Simulink\footnote{www.mathworks.com/products/simulink/}, developed by The Mathworks is a graphical modeling environment. Simulink can be used in the  process of designing embedded systems. It allows the simulation of embedded systems with the controlled physical processes. Models are built graphically in Simulink using block diagrams. In addition, Simulink is integrated in MATLAB which allows the incorporation of MATLAB functions in Simulink models. Finally, Simulink enables automatic code generation from models.

\subsubsection{Modelica}
Modelica is an object-oriented equation-based language for the modeling of complex physical systems developed by the Modelica Association. Modelica allows the modeling of physical systems by writing a set of equations. Modelica adopts an acausal approach, i.e. the signal flow is not specified in the model. The simulator has to perform symbolic manipulations in order to define inputs and outputs and find an order of execution for these equations. There exist several tools that are based on the Modelica language.

OpenModelica\footnote{www.openmodelica.org} is an open-source modeling and simulation environment based on the Modelica language. It is developed and maintained by the Open Source Modelica Consortium (OSMC). OpenModelica supports the FMI for Model Exchange standard.

Dymola\footnote{www.3ds.com/products-services/catia/products/dymola}, developed by Dassault Syst\`emes AB, is a modeling and simulation environment based on the Modelica modeling language. Dymola supports the FMI standard and allows interfacing with other tools such as Simulink

\subsubsection{LMS Imagine.Lab Amesim}
LMS Imagine.Lab Amesim\footnote{www.plm.automation.siemens.com/en\_us/products/lms/imagine-lab/amesim/} is a modeling and simulation software developed by Siemens PLM Software. It can be used for the modeling and simulation of mechatronic systems. It is based on the Modelica modeling language. It is oriented towards the modeling of complex physical systems instead of controller design. LMS Imagine.Lab Amesim provides libraries containing collections of components that can be loaded and connected by the user to build models. For simulation, LMS Imagine.Lab Amesim automatically selects a solver that is adapted to the problem. It supports the FMI standard.

\subsubsection{xMOD}
xMOD\footnote{www.xmodsoftware.com/} is the modeling and co-simulation software developed by IFP Energies nouvelles. It supports FMI and provides an environment for the integration of heterogeneous models built by different parties using different languages and tools. xMOD can execute models with different integration and communication step sizes. Also, it allows the co-simulation of models embedding different solvers or not. In the latter case, xMOD provides a list of different solvers from which the user can choose one for every model. xMOD does not replace original modeling and simulation tools. Instead, it promotes and facilitates their coupling and existence.

\subsubsection{CosiMate}

CosiMate\footnote{www.cosimate.com/} is a co-simulation environment that enables distributed co-simulation. Multiple simulators can be executed on different computers and communicate over a network. CosiMate supports the FMI standard, interfacing with Simulink, and several languages like Modelica, C++, and Java.

\subsubsection{Hopsan}
Hopsan\footnote{www.iei.liu.se/flumes/system-simulation/hopsan?l=en} is a free multi-domain system co-simulation tool developed at the division of Fluid and Mechatronic Systems at Link\"oping university. Hopsan supports the FMI standard and model export to Simulink.

\section{Parallel Computing}

Parallel computing is a very important branch in the computing research and industry. It refers to the discipline that focuses on executing multiple computations simultaneously to solve one problem. Its basic idea is to divide a computing task into several sub-tasks that can be performed at the same time. From the beginning of the modern era of computing, computer software has been typically written for sequential execution. In order to solve a problem, an algorithm is designed as a sequence of instructions that are executed one after the other. In order to increase the computation power of computers, the dominant method was frequency scaling. If a processor's frequency is increased, it means that it can execute more instructions per clock cycle and thus can execute a sequential program faster. Moore's law predicted that the number of transistors in a processor would double approximately every two years \cite{moore:1965}. This prediction proved correct for many years. However, frequency scaling is facing technological limits and the last decade witnessed a wide shift to multicore processors among semiconductor manufacturers. Moore's law can be considered to be still accurate since more transistors are still integrated in chips, not for frequency scaling but to add more processing elements. The rise of multicore processors has caused the evolution of many parallel hardware and software technologies.

The main goal of parallel computing is to execute computer programs faster. The speedup obtained from the parallelization can be predicted using Amdhal's law \cite{amdahl:1967}. It states that for a program that is paralellized in order to be executed on multiple processors, the portion of the program that has to be executed sequentially will limit the speedup. The speedup is therefore not linear with the number of processors and probably adding more processors will not make the program run faster. The following formula gives the theoretical speedup computed using Amdahl's law.
\begin{equation}
S(n) = \frac{1}{(1-P) + \frac{P}{n}}
\end{equation}
$S(n)$ is the theoretical speedup, $P$ is the portion of the program that can be parallelized and $n$ is the number of processors. Figure \ref{fig:amdhal} shows the theoretical speedup of a program in function of the number of processors for different values of $P$. It shows for example that if $50\%$ of a program can be parallelized, the maximum possible speedup is 2, and if $95\%$ of the program can be prallelized, the maximum speedup is around 20.

\begin{figure}[phbt]
\centering
\captionsetup{justification=centering}
\includestandalone{figures/amdhal}
\caption{Theoretical speedup computed using Amdahl’s law for a program in function of the number of processors for different values of P.}
\label{fig:amdhal}
\end{figure} 

\subsection{Parallel Architectures}

Parallel computers are of many types, some of which are adapted only to specific kinds of applications. Parallel computers can be classified according to different criteria. Below, we present the common classifications of parallel computers. 

\subsubsection{Flynn's Taxonomy}

The well-known Flynn's taxonomy \cite{flynn:1972} classifies computers according to instruction and data streams into the following categories:

\paragraph{Single-Instruction Stream--Single-Data Stream (SISD)}

This is the basic uniprocessor which does not exhibit any parallelism. The execution is sequential where a single instruction stream operates on single data stream. Examples of such architecture are old desktop computers.

\paragraph{Single-Instruction Stream--Multiple-Data Streams (SIMD)}

A SIMD computer executes the same instruction on multiple data streams in parallel. A Graphics Processing Unit (GPU) is one example of SIMD architectures.

\paragraph{Multiple Instruction-Streams--Single Data Stream (MISD)}

Multiple instructions are executed on a single data stream. For example, in fault-tolerant computing, the same operation is performed in parallel and the results of all the computations must be the same.

\paragraph{Multiple Instruction-Streams--Multiple Data Streams (MIMD)}

Different instructions are executed on different data in parallel. Examples of MIMD computers include multi-core architectures, grid computers, and supercomputers.

\subsubsection{Memory Models}

Flynn's taxonomy differentiates parallel computers based on their operational behavior. Another important classification of parallel computers is the one based on the organization of the memory.

\paragraph{Shared Memory}

In this class of parallel architectures, a common memory is shared among multiple processors. All processors access the same global shared memory by operating on a single address space. Communication between the processors is performed through shared memory variables. Shared memory multiprocessors have the advantage of low communication overhead thanks to the proximity of the memory to processors. Scalability is a disadvantage of shared memory multiprocessors as increasing the number of processors creates more traffic between the processors and the memory.

There are two kinds of shared memory designs, Uniform Memory Access (UMA) and Non-Uniform Memory Access (NUMA). In the UMA design, the time needed to access the memory is the same for all the processors. This architecture is referred to as Symmetric Multiprocessor also. In the NUMA design, each processor has a local memory, and the shared memory is composed of these local memories. Time to access a specific memory region is not uniform for all processors. Processors access their local memories faster than the local memories of other processors.

\paragraph{Message Passing}

In the message passing model, also known as distributed memory, each processor has its own memory. Each processor operates on a distinct address space and is only able to access its own memory. As the name suggests, communication between the processors is performed by explicitly passing messages. If a processor needs data from another processor, it explicitly sends a request to this processor and waits for its response. An advantage of the distributed memory architecture is the scalability. If the number of processors is increased, memory is increased also. A disadvantage of the distributed memory architecture is the time needed to passe messages between processors. This time becomes large in the case of huge number of processors or long distances between the processors. A typical distributed memory computer is a set of standalone computers interconnected via a network, e.g. Ethernet.

\paragraph{Hybrid Memory}

It is possible to use both shared and distributed memory in a computer. In this hybrid model, shared memory processors are connected via a network to form a distributed memory architecture. This is the dominant memory architecture in supercomputers today.

\subsection{Parallelism in Software}

Much progress has been made in the design of parallel architectures. That being said, taking advantage of such architectures requires efficient ways for executing applications on parallel architectures. A difficult yet integral step in this direction is the process of detecting the parallelism that is inherent in software. It is important that this parallelism can be classified into different categories based on the nature of computations that are performed. The main classes of software parallelism are the following:    

\subsubsection{Data parallelism}
Data parallelism is characterized by performing the same computation on a large set of data. If several processors are available, the data can be distributed across them and the same computation is executed on each processor. For instance a for loop can be parallelized by distributing the iterations over multiple processors. The same body of the for loop is executed on all the processors but operates on a different range of iterations on each processor.

\subsubsection{Task parallelism}
In task parallelism, a program is divided into different computational tasks that are distributed across the processors to be performed in parallel. The challenge here is the question of how to divide the program efficiently so as to obtain the best speedup. In task parallelism, tasks can operate on different data sets. Usually, dependencies exist between the tasks, e.g. the result of one task is needed as input by another task.

\subsubsection{Pipeline Parallelism}

Pipeline parallelism combines data and task parallelisms. Multiple tasks operate on streams of data and are executed repeatedly in a sequence. Each task takes its input from the preceding task and produces output to the next task. When a task finishes processing a data element it passes it to the next task and starts processing a new data element even if the next task has not finished processing. Pipeline processing is common in streaming applications such as video streaming. 

\subsection{Parallel Programming}

In order to efficiently map software parallelism on parallel architectures, many parallel programming libraries, APIs, and standards have been developed. Basically they differ according to the targeted type of memory.

\subsubsection{Shared Memory Programming}

Shared memory programming is based on threads. Multiple threads are created and executed on multiple processors. The programmer does not need to worry about the communication between threads as this is done implicitly via shared variables. Threads may have private variables that are not shared with the other threads. Data consistency problem occurs if two or more threads attempt to write data to the same memory location. Threads must coordinate using synchronization mechanisms in order to avoid data consistency problems. There are many libraries and APIs for shared memory programming. The following are some examples.

Open Multi-Processing (OpenMP) \cite{openmp} is an API that has been designed to develop applications that are meant to be executed on shared memory parallel computers such as multicore computers. OpenMP is supported by C, C++ and Fortran programming languages. The basic idea of OpenMP is that a master thread is responsible for the creation of slave threads that are allocated to processors to run in parallel. The creation of slave threads is called forking. It is the duty of the developer to specify parts of the code that can run in parallel using preprocessor directives. These directives cause the threads to be created before their execution. When the execution of the slave threads is finished, they join back to the master thread which continues the execution of the program. OpenMP can be used for both data and task parallelism.

Intel Threading Building Blocks (Intel TBB) \cite{reinders:2007} is a C++ parallel programming library. Using Intel TBB, the developer specifies the parallelism in the form of tasks, not threads. These tasks are automatically mapped by the library onto threads. Intel TBB uses work stealing, i.e. it dynamically tries to balance the computation load among the available processors at runtime.

Shared memory programming can be done using low level multi-threading also. For instance by using POSIX threads (pthreads) or Windows threads. Such low-level approach gives the developer more flexibility and control over the threads, e.g. thread creation and mapping, compared to using libraries such as OpenMP or Intel TBB. Nonetheless, the latter are simpler to use. 

\subsubsection{Distributed Memory Programming}

Distributed memory programming is done using processes that are executed on different processors. The data needs to be partitioned and mapped to the processors with the corresponding tasks. Data is moved between processors if needed. An important challenge is to keep data exchange as low as possible in order to minimize the communication between the processors. Data consistency is not a concern in distributed programming, since each process only writes to the local memory. Nevertheless, the developer needs to implicitly specify the communication between the processors through message passing.  

The classical standard for distributed memory programming is the Message Passing Interface (MPI) \cite{mpi}. MPI is a standard for programming distributed memory parallel computers. It is supported by many programming languages and platforms. It defines a communication protocol for performing the message passing and provides communication and synchronization functionalities for collaborating processes that are allocated to different processors. It supports different kinds of communications such as point-to-point and collective communication. It is also possible to choose the topology of communication to be used.

\subsection{Parallel Scheduling}

Parallelization consists in the transformation of a sequential program into a multithreaded one in order to be executed on multiple processors. In order to be parallelized, a program needs to be modeled in such a way to express the available parallelism. In general, a model of a program can be made by dividing the program into tasks of computations and defining dependence between them. 
If the number of the tasks is equal to the number of processors, the parallelization of the program can be achieved by allocating each task to a distinct processor. However, this is not the case in practice, i.e. there are much more tasks than processors. In this case multiple tasks are allocated to one processor and executed sequentially.  
Knowing the time needed to execute each task is also important to model the program. Depending on the application, other properties and constraints can be considered. Having a model of the program, the parallelization consists in defining a schedule for the different tasks, i.e. an allocation to a processor and a time for starting the execution of each task. Parallel computing has received much interest in the scheduling theory community and many algorithms and models have been proposed to solve the problem of application parallelization.   

Scheduling in the broad sense refers to the theory, algorithms and systems that deal with problems of sequencing and allocating tasks to resources. Scheduling theory has numerous areas of application like manufacturing, transportation, logistics, sports scheduling, and project management. The objective of scheduling for parallel computing is to take full advantage of a parallel architecture for the execution of a parallel application . A significant part of the research carried out in the scheduling theory field treats problems related to scheduling computational tasks on parallel computers. This kind of scheduling is known as parallel scheduling. We focus in this section on parallel scheduling from a computing point of view.

In a parallel scheduling problem, the resources are the processors (or cores of a mult-icore processor) and the tasks are the computation functions of the application to be executed. Resources are traditionally referred to as computers, or sometimes machines, and tasks as jobs. We use the terms processors, to refer to processing elements of a parallel computing system, and tasks to refer to the computational tasks of the application to be executed. A set of $n$ tasks is denoted $T = \{t_1, t_2, \ldots, t_n\}$ and a set of $m$ processors is denoted $P = \{p_1, p_2, \ldots, p_m\}$. Scheduling consists allocating tasks form $T$ to processors from $P$ with respect to predefined criteria. Scheduling implies also the definition of an execution order for the tasks that are allocated to the same processor by setting execution start times for the tasks. In general, each task has to be allocated to one and only one processor and a processor can execute at most one task at a time. Additional constraints can be considered depending on the problem.

In scheduling problems, processors can be classified based on their speed of execution \cite{davis:2011}:

\begin{itemize}
\item \textit{Heterogeneous}: The execution speed of a task depends on both the processor and the task. Not all tasks may be executed on all processors.
\item \textit{Homogeneous}: The processors are identical. The execution speed of a given task is the same on all processors.
\item \textit{Uniform}: The execution speed of a task depends only on the speed of the processor. A processor of speed 2 will execute all tasks at exactly twice the speed of a processor of speed 1.
\end{itemize}

A schedule is called preemptive if a the execution of a task can be preempted and resumed later. If a schedule is not preemptive, it is called non preemptive. Furthermore, a scheduling algorithm is either dynamic or static. Dynamic scheduling algorithms are used when some information about the tasks are not known before the execution. The scheduling algorithm makes scheduling decisions online as the information becomes available. Static scheduling algorithms can be used when the characteristics of the tasks, such as dependence between them and their execution times, are known before the execution. It is then possible to compute the schedule of the tasks offline.

Scheduling research has been active for over 60 years now and so many methods and algorithms have been proposed to solve different scheduling problems. Different performance measures can be considered such as the makespan objective, the total completion time objective, and the number of late tasks objective \cite{leung:2004}. Makepsan is the time needed by a computer to process a set of tasks. The general objective of parallel computing is to accelerate the execution of application which corresponds to the makespan objective.

\subsubsection{Task Dependence Graph}

A set of tasks which express the parallelism of an application can be represented by a Directed Acyclic Graph (DAG) $G(V,A)$ called the task dependence graph. Each task is represented by a vertex $v_i \in V: 0 \leq i < n$ where $n$ is the number of tasks. Dependence between tasks is represented by arcs $(v_i, v_j) \in A: 0 \leq i,j < n$. A vertex may have one or more incoming edges which connect it with its predecessors and one or more outgoing edges which connect it with its successors. A task cannot start its execution unless all its predecessors have finished the execution. Generally, dependence between two tasks is due to data movement, i.e. one task is executed and produces a data element, and the second task requires this data element to start its execution. If a vertex has no predecessor it is called an entry or source vertex. A vertex that has no successor is called an exit or sink vertex. The vertices may be weighted by the execution times of the corresponding tasks (see Figure \ref{fig:dagex}). In the remainder of the thesis we will use the term dependence graph instead of task dependence graph.

\begin{figure}[phbt]
\centering
\includestandalone{figures/dagex}
\caption{Example of a task dependence graph.}
\label{fig:dagex}
\end{figure} 

\subsubsection{Potential and Effective Parallelisms}

In industrial practice, we distinguish between the "functional" and "non functional" specifications. Functional specification consists in defining what has to be done. Mainly, the different functions of the application and the dependence between them are specified. Non functional specification consists in defining how the functions have to be performed. It provides a description of the hardware architecture, its different components and how they are interconnected. It specifies also allocation constraints if there are any and the timing parameters of the different functions, such as their execution times and periods.

Having both the functional and non functional specifications, the "potential" and the "effective" parallelisms can be deduced. The potential parallelism is related to the functional specification. It is defined by the functions that are not dependent as they can be executed in parallel, e.g. $t_2$ and $t_3$ in Figure \ref{fig:dagex}. The effective parallelism is defined by the hardware architecture, i.e. how many processing elements (processors, cores, \ldots) are able to execute functions in parallel. If the effective parallelism is less or equal to the potential parallelism, the execution of the application is accelerated. If it is greater, the execution is accelerated also but, no matter how much the effective parallelism is increased, the speedup remains constant. This can be interpreted by Amdahl's law because which describes how hardware parallelism limits the exhibition of the application parallelism.


\subsubsection{List Scheduling}

Heuristics are usually used to solve parallel scheduling problems because these problems are NP-copmlete [gary] and using exact algorithms results in exponentially increasing execution times. In particular, list scheduling heuristics have been successfully used in the context of static scheduling. All list scheduling heuristics are based on the same idea. Tasks that are ready to be scheduled are kept in a list. A task becomes ready to be scheduled once all its predecessors have been scheduled. The heuristic assigns priorities to the tasks in the list and selects the task with the highest priority to schedule it. This process is repeated untill all the tasks have been scheduled. The way the priorities of tasks are computed differs from one list scheduling heuristic to another. In the following we review list scheduling heuristics that are proposed in the literature for makespan minimization.

A well-known algorithm in the literature to minimize the makespan of a graph with no transitive arcs is Hu's algorithm \cite{hu:1961}. It assigns a level to each vertex in G as follows: All vertices that have no immediate successor are at level 1. Then for each of the other vertices, the level is equal to one plus the maximum level of its immediate successors. Hu's algorithm proceeds repeatedly by allocating each time the ready task (whose all immediate predecessors have already been allocated) and which has the highest level among all ready tasks to the first available processor. 

Coffman-Graham algorithm \cite{coffman:1972} performs the scheduling in two steps. First a task is labeled with a label which is a function of the labels of its immediate successors (the labeling algorithm is not detailed here). Tasks are then allocated following a highest label first policy. 

Papadimitriou and Yannakakis \cite{papadimitriou:1979} studied the problem of scheduling interval-ordered task graphs. In such a graph, two vertices are precedence-related if and only if they can be mapped to non-overlapping intervals on the real line \cite{fishburn:1985}. A task is assigned a priority based on the number of its successors. A list of the tasks is constructed in a descending order of their priorities and then the tasks are assigned in this order. 

In \cite{adam:1974} level-based algorithms for scheduling dependence graphs are presented. The proposed Highest Level First with Estimated Times algorithm labels the vertices of the DAG with levels where the level corresponds to the sum of computation costs on the longest path from the vertex to a sink vertex. It then allocates the tasks in a highest-level first fashion, therefore, the level of a task represents its priority. Highest Levels First with No Estimated Times algorithm works similarly but with the assumption that all tasks have unit computation costs. \cite{kasahara:1984} proposes a similar algorithm with the improvement of breaking ties by selecting the vertex with the largest number of successors. 

In \cite{shirazi:1990} two algorithms are proposed: First, the Heavy Node First algorithm which is based on a local analysis of the vertices at each level. It allocates the heaviest vertice first. The second algorithm, WL (Weighted Length), considers a global view of the dependence graph by taking into account the relationships among the nodes at different levels. 

\cite{kruatrachue:1987} proposed the ISH algorithm. The main idea of ISH is to fill the "scheduling holes"  which are the idle time slots as the schedule is being constructed.

The MCP (Modified Critical Path) algorithm proposed by \cite{wu:1990} uses the measure of how late can a task be delayed without increasing the makespan of the schedule. MCP assigns priorities to tasks in an ascending order of their latest start dates. 

The Earliest Start Time algorithm \cite{hwang:1989} computes at each step, for each task, the earliest start date and selects the task that has the smallest one to allocate it. 

The DLS (Dynamic Level Scheduling) algorithm \cite{sih:1993} assigns dynamic levels to tasks. The dynamic level of a task is equal to the difference between the b-level (longest path from the corresponding vertice to a sink vertice) of the task and its earliest start date. At each step, the algorithm computes the dynamic levels for the ready tasks on all processors. The task-processor pair that gives the largest DL is selected for scheduling. 

In \cite{yang:1994} Yang and Gerasoulis present the DSC algorithm which uses an attribute called the dominant sequence which is the critical path of the partially ordered graph.

A current trend in multiprocessor scheduling is to use meta-heuristics such as Genetic Algorithms (GA) \cite{hou:1994, wu:2004, omara:2010}.

\subsection{Parallel Real-time Scheduling}

Real-time scheduling concerns the scheduling of tasks in real-time systems. Real-time does not mean fast, instead, it refers to systems that must be able to respond to external events within specified deadlines. Real-time systems are typically found in the form of embedded systems that control physical processes. They represent the cyber part in a CPS. In general, real-time systems are computing systems that are characterized by timing constraints in addition to the functional requirements. A part of this thesis deals with HiL simulation which can be qualified as a real-time system because the simulated part has to meet predefined deadlines in order to ensure correct results.
In order to implement real-time applications, first, \textit{real-time tasks} are defined by characterizing the functions obtained from the functional specification by a number of timing parameters. A real-time task denoted $t_i$ is characterized by the following parameters (see Figure \ref{fig:taskmodel}):
\begin{itemize}
\item Release time $r^k_i$: Typical real-time applications consist of a set of tasks that are executed repeatedly where each execution is called an instance. The time at which an instance becomes ready to be executed is called the activation or the release time. $r^k_i$ is the release time of the $k^{th}$ instance of the task $t_i$;
\item First release time: $r^0_i$, called also offset;
\item Start time $s^k_i$: The time at which the $k^{th}$ instance starts its execution $(s^k_i \geq r^k_i)$;
\item Execution time $C_i$: A real-time task has an execution time which cannot be considered to be fixed and may vary from one execution to another. Therefore, a real-time task is characterized by its Worst Case Execution Time (WCET);
\item Finishing time $f^k_i$: The time at which the $k^{th}$ instance finishes its execution;
\item Response time $R^k_i$: The duration between the release time and the finishing time of the $k^{th}$ instance: $R^k_i = f^k_i - r^k_i$;
\item Absolute deadline $d^k_i$: The time at which the $k^{th}$ instance must finish its execution;
\item Relative deadline $D_i$: Starting from the release time, the duration within which the task has to finish its execution;
\item Laxity $l^k_i(t)$: Difference between the absolute deadline and the time for which the task has been running $l^k_i=d^k_i-(t+C_i(t))$.
\end{itemize}

In addition, real-time tasks are characterized by a parameter related to how consecutive instances of a task are activated. Three kinds of tasks can be distinguished:
\begin{itemize}
\item Periodic tasks: The instances of a given task are activated periodically with a known period. A periodic task is characterized by its period $T_i$;
\item Sporadic tasks: The instances of a task are activated by an event and the minimum time between two successive activations is known. A sporadic task is characterized by $T_i$, its minimum arrival time;
\item Aperiodic tasks: The minimum delay between two activations is not known.
\end{itemize} 

\begin{figure}[phbt]
\centering
\includestandalone{figures/taskmodel}
\caption{Parameters of a real-time task.}
\label{fig:taskmodel}
\end{figure} 

Real-time systems can be classified based on the impact of missing deadlines. Hard real-time systems are systems where all deadlines must be met. Violating this constraint leads to the failure of the system and may result in a great loss such as serious injuries, threatening human life, or damaging the surroundings. Soft real-time systems can tolerate some deadlines to be missed but the quality of the result degrades consequently. Firm real-time systems allow few deadlines to be missed but if a task's deadline is missed, its result is no more useful. We consider that HiL simulation falls within the category of firm real-time systems. In fact, in order to have correct HiL results, deadlines must be met. If a task misses its deadline, it produces erroneous results and probably causes the failure of the system but the consequences are not as catastrophic and harming as in the case of hard real-time systems.   

Many different real-time scheduling algorithms have been proposed in the literature but they are all based on the same idea, tasks are assigned priorities and then scheduled in an order following their priorities. We distinguish between fixed priorities which do not change during the execution and dynamic priorities which may be changed by the scheduler during the execution. Also, as in other kinds of scheduling problems, real-time scheduling algorithms can be classified into offline/online and preemptive/non preemptive algorithms.

The main goal of scheduling in real-time systems is to satisfy the different timing constraints of the tasks. Schedulability tests can be used to check whether the tasks can be scheduled using a given scheduling algorithm in such a way to satisfy all the requirements. A schedulability test verifies if the utilization or the density of the processor, defined below, when it executes the set of tasks under test, is within a least upper bound. For a set of $n$ independent periodic tasks, the utilization factor and density, when a preemptive scheduling algorithm is used, are respectively:

\begin{equation}
U = \sum_{i=1}^{n}\frac{C_i}{T_i}
\end{equation}

\begin{equation}
\Delta = \sum_{i=1}^{n}\frac{C_i}{D_i}
\end{equation}
The most known real-time scheduling algorithms are the following:

\begin{itemize}
\item Fixed priorities
\begin{itemize}
\item Rate Monotonic (RM): Tasks are assigned priorities inversely proportional to their periods. A set of tasks is schedulable by RM if: $U \leq n(2^{\frac{1}{n}}-1)$, $D_i = T_i$. 
\item Deadline Monotonic (DM): Tasks are assigned priorities inversely proportional to their relative deadlines. Tasks are schedulable using DM if: $\Delta \leq n(2^{\frac{1}{n}}-1)$, $D_i \leq T_i$. 
\end{itemize}
\item Dynamic priorities
\begin{itemize}
\item Earliest Deadline First (EDF): Priorities of tasks are inversely proportional to their absolute deadlines. The priority of a task is fixed for one instance but may change from one instance to another. EDF can schedule a set of tasks iff: $U \leq 1, D_i = T_i$.
\item Least Laxity First (LLF): Priorities of tasks are inversely proportional to their laxities. The priority may change for the same instance and from one instance to another. The schedulability test is the same as for EDF.
\end{itemize}
\end{itemize}
 For multiprocessor real-time scheduling, there exist two principal approaches:

\begin{itemize}
\item Global scheduling: Each task can be scheduled on any processor. the scheduler is responsible for migrating the tasks between the processors.
\item Partitioned scheduling: The tasks are partitioned into groups, each of which is allocated to one processor. Each processor has a single-processor scheduler. 
\end{itemize}
Global multiprocessor scheduling has significant overhead due to the migration cost. Thus is the reason why partitioned scheduling is usually used in hard real-time systems. Partitioning and allocating a set of tasks is equivalent to the "Bin Packing" problem which is NP-hard and heuristics are therefore used. 

Assuming the tasks are sorted in a list and that processors are organized in a certain order, the most known heuristics that can be used to allocate a set of tasks to multiple processors are:

\begin{itemize}
\item First Fit (FF): A task is tested on all cores and for each task the test starts from the first core. The task is allocated to the first found core that can schedule it. A task is schedulable on a given core if by allocating it to this core the condition $(U\leq1)$ is valid where $U$ is the utilization of the core.
\item Next Fit (NF): Similar to FF but the search of the core that can schedule the task does not start always from the first one. After allocating a task to a core, the core search for the next task starts from the next core.
\item Best Fit (BF): Test the task on all cores and allocate it to the one that gives the minimum of $U$.
\item Worst Fit (WF): Allocate the task to the core that gives the maximum of $U$.
\end{itemize}
  
\subsection{Parallel Execution}

It is important to understand how the previously presented concepts of parallel computing are related. These concepts are involved in parallelization which refers to the process that takes as input a sequential code and achieves a parallel execution of the program. The first step of parallelization consists in detecting the potential parallelism of the program. Depending on the class of parallelism (e.g. task or data), a model, such as a dependence graph, is used in order to represent this potential parallelism. The targeted parallel architecture has to be modeled as well in order to accomplish the parallelism adaptation. Given the models of the potential parallelism and the effective parallelism, a schedule has to be found. In other words, the different parts of the program are allocated to the different components of the parallel architecture and their execution is ordered. Finally, based on the computed schedule, a parallel code is generated to be executed on the parallel architecture.  

\subsubsection{The AAA Methodology and SynDEx Software}

The goal of the Algorithm-Architecture-Adequation (AAA) methodology \cite{sorel:1996} is to find out the best implementation of an algorithm specifying the functions the application has to perform onto a multicomponent architecture, while satisfying real-time and embedding constraints. The AAA methodology is based on graphs models to exhibit both the potential parallelism of the application algorithm and the available parallelism of the hardware architecture.  Adequation means an efficient implementation. The implementation consists in distributing and scheduling the algorithm graph onto the multicomponent graph while satisfying real-time constraints. This is formalized in terms of graph transformations. Heuristics based on distributed real-time scheduling analyses taking into account timing characteristics attached to operations (period, worst case execution time of computations and of inter-component communications), are used to automatically explore the possible implementations of a given application onto a given multicomponent hardware that satisfy real-time constraints, and to optimize the reaction time as well as resources allocation. The result of graph transformations is an optimized Synchronized Distributed Executive (SynDEx) dedicated to the application, automatically built from a library of architecture dependent executive primitives composing each executive kernel. (Figure \ref{fig:aaa}).

\begin{figure}[phbt]
\centering
\includestandalone{figures/aaa}
\caption{The Algorithm-Architecture-Adequation methodology.}
\label{fig:aaa}
\end{figure} 

\section{Parallel Execution of Co-simulation}

The more accurate is a simulation of a system, the more reliable is the assessment of its behavior. The numerical accuracy can be improved in different ways, for instance, by choosing a small integration step size. However, this means that more computations are performed and thus the computation load becomes large decreasing the simulation performance. An important challenge faced by the developers and the users of simulation tools is to achieve a good simulation performance while maintaining an acceptable simulation accuracy. 

The performance of a simulation can be significantly improved through parallel execution. In this scope, different approaches for the parallelization of simulations have been porposed in the literature. In this section we briefly review some of the approaches for the parallelization of simulation that are found in the literature. We present also some of the available simulation tools that support parallel simulations.

\subsection{\label{subsec:parsimaprr}Approaches}

In order to achieve simulation acceleration through parallel execution, different approaches are possible and were already explored. The parallelization approaches can be classified into three categories based on the level at which the parallelization is intorduced.

\subsubsection{Parallelization across the method}
In this category, we find approaches that seek to parallelize the integration method. For instance, a multi-satge solver requires several computations within one integration step and it is possible to perform multiple computations within one step in parallel. Such approach is studied in \cite{iserles:1990} by proposing a theoretical framework for parallelization of Runge-Kutta methods. Another approach consists in parallelizing operations on vectors for ODEs resolution like in the PVODE solver \cite{byrne:1999} implemented using MPI. 

In \cite{elmqvist:2015}, the authors propose a method for parallelization of modelica programs on CUDA-enabled GPUs. The proposed method relies on marking the functions to be executed on the GPU by identifying patterns that are GPU suitable such as loops. These functions are then automatically translated into GPU code. In \cite{Gebremedhin2012}, ParModelica, an algorithmic extension to Modelica is proposed. This extension is based on OpenCL and allows stating the parallelism using special declarations in the code. An approach for automatic parallelization of equations on many-core platforms is proposed in \cite{elmqvist:2014}. This approach organizes the equations into a set of layers containing each a number of sections that can be executed in parallel and computes a static schedule for their execution. In \cite{clauberg:2012} an approach for the parallelization of multi-body simulations on shared memory multiprocessors is processors. This approach uses math-kernel libraries and OpenMP to parallelize matrix operations.

\subsubsection{Parallelization across the time}

A simulation can be parallelized across the time steps. Examples of such approach are the Parreal algorithm \cite{lions:2001}, the Parallel Implicit Time-Integrator (PITA) \cite{farhat:2003}, and the Parallel Full Approximation Scheme in Space and Time (PFASST) \cite{emmett:2012}. These methods divide the time domain into a two-level grid. A solution is evaluated in parallel over a fine time grid to improve a solution obtained sequentially over a coarse time grid.
\subsubsection{Parallelization across the system}

Finally, a simulation can be parallelized across the system, i.e. the equations of the simulation are solved in parallel. A well known approach that parallelizes across the system is Waveform Relaxation (WR) \cite{lelarasmee:1982}, initially introduced for the simulation of large scale integrated circuits. The WR method breaks down the system into coupled subsystems of equations and computes the waveform, i.e. the solution, of each subsystem over a given time interval while fixing the waveforms of the other subsystems. The parallelization is made possible by computing the waveforms of several subsystems in parallel. 

Transmission Line Modeling (TLM) \cite{hui:1990} is a method that allows the decoupling and the parallelization of models by representing them using transmission line graphs such that decoupling points are chosen where variables change slowly because the models are considered to be connected by constants at these points. The approaches presented in \cite{sjolund:2010,braun:2012} are based on the TLM method. 

Co-simulation is naturally adapted to parallelization across the system. In fact, as shown in \cite{Benkhaled_A_2012_ECOSM}, splitting a model into several FMUs, by isolating discontinuities, may reduce the simulation time, even in the case of a sequential execution. In \cite{benkhaled:2014} the Refined CO-SIMulation (RCOSIM) approach is presented. It consists in using each FMU information on input/output causality to build a graph, with an increased granularity and then exploiting the potential parallelism by using a heuristic to build an offline multi-core schedule.

\subsection{Tools}

More and more simulation tools are now endowed with parallel execution capabilities. However, it should be noted that some of these tools adopt parallelization approaches that do not target the numerical part of the simulation. For instance, the Parallel Computing Toolbox in MATLAB allows launching multiple Simulink simulations of the same model in parallel on a desktop multi-core computer or a cluster. These are separate independent simulations of the same model. Thus, this feature does not correspond to the focus of this thesis, i.e. the parallelization of the numerical computations of a simulation. Also, Simulink provides an execution mode known as Rapid Accelerator Mode which consists in creating a standalone executable of the model and the solver. Simulink runs in one process and this executable runs in another process on a multi-core processor. Again, although this approach may improve the performance of the simulation, it does not lie within the scope of the thesis.

The Dymola tool enables automatic parallelization of equation resolution. The prallelization approach of Dymola is detailed in \cite{elmqvist:2014}. LMS Imagine.Lab Amesim allows launching multiple simulations in parallel, for example to run a model with different parameters. It has also the capability of partitioning models and executing them on multi-core processors. The TLM method, presented above, is integrated in the Hopsan tool. Finally, MBSim parallelizes matrix and vector operations as described in \cite{clauberg:2012}. The co-simulation software xMOD is able to execute FMI co-simulations in parallel on multi-core architectures. It uses the RCOSIM approach \cite{benkhaled:2014} presented in section \ref{subsec:parsimaprr}.  