\chapter{\label{ch:3-state}Problem Position} 

\minitoc

In the foregoing part of the thesis, we presented the background of the involved research work. We presented preliminary concepts and state of the art review regarding the different topics that are involved in this thesis. In this chapter, we detail the research problem of the thesis. We give an overview of the adopted methods and explain the research questions that this thesis attempts to solve.

\section{Overview}

This thesis addresses the problem of parallel execution of co-simulation. We are interested in co-simulations that are compliant with the FMI standard. Both FMI for Model Exchange and FMI for Co-Simulation are of interest in this thesis. In particular, we focus on closed-source FMI co-simulations, i.e. co-simulations for which functions are provided as executable binaries and the source code is not accessible.

From a hardware standpoint, we target share-memory architectures, more specifically multi-core architectures such as the ones found in desktop and laptop computers.

Finally, the research carried out in this thesis can be divided into two parts. The first part deals with accelerated co-simulation, i.e. the goal of the paralleization of the co-simulation is to accelerate its execution on multi-core architectures. In the second part, we focus on real-time co-simulation. The goal of this part is to satisfy the requirements for a real-time execution of the co-simulation through parallelization on multi-core architectures.

\section{The RCOSIM Approach}

The contributions of this thesis constitute improvements to the RCOSIM approach presented in section \ref{subsec:parsimaprr}. The RCOSIM approach is based on offline multi-core scheduling. First, it transforms the co-simulation FMU graph into a dependence graph with finer granularity. This process is explained in section \ref{sec:4-depgrph}. A multi-core list scheduling heuristic is then used to compute a schedule for this dependence graph, i.e. an allocations of its vertices, wich represetn functions, to the cores and an order of execution for the vertices that are allocated to each core. The execution of the co-simulation consisting in running this schedule repeatedly.

In this thesis, we chose to build on the RCOSIM approach in order to achieve parallelization of FMI co-simulations for both accelerated and real-time execution. We did not use known parallel programming libraries for specific reasons. It is clear that MPI is not suitable for our goal since we target shared memory architectures whereas MPI is used to program distributed memory architectures. The other option is use OpenMP or similar libraries which are adapted to shared-memory architectures. However, OpenMP is efficient especially in the case of data parallelism (e.g. loop parallelism) which is not apparent in the co-simulations that we target. In fact, since we do not have access to the source code of the functions, we can not perform parallelization of the functions, e.g. solver function, by using OpenMP pragmas. We only have information about the application at the function level. It should be noted that libraries such as OpenMP and Intel TBB offer task programming features which can be used for our purpose. However, they rely on online scheduling which may introduce high overhead and thus decreases the performance. In addition, given that information about dependence between functions is available and the execution times can be measured, we assume that offline scheduling is more efficient to achieve our goal   

\section{RCOSIM Limitations}

\section{Research Questions}