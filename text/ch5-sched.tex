\chapter{\label{ch:5-rtsim}Multi-core Scheduling of FMU Dependence Graphs} 

\minitoc

This chapter presents methods for scheduling an FMU dependence graph on a multi-core architecture. Once the dependence graph has been constructed and undergone the different phases of transformations as shown in the previous chapter, it is scheduled on the multi-core platform. First, we consider scheduling the dependence graph with the goal of accelerating the execution of co-simulation. Second, we consider scheduling the dependence graph while satisfying real-time constraints.  

\section{Scheduling of FMU Dependence Graphs for Co-simulation Acceleration}

In order to achieve fast execution of the co-simulation on a multi-core processor, an efficient allocation and scheduling of the operation graph has to be achieved. The scheduling algorithm takes into account functional and non functional specification in order to produce a mapping of the dependence graph vertices (operations) to the cores of the processor, and assign a starting time to each operation. We present here-after a linear programming model and a heuristic for scheduling FMU dependence graphs on multi-core processors with the aim of accelerating the execution of the co-simulation.

\subsection{\label{5:shed-prob}Problem Formulation}

The acceleration of the co-simulation corresponds to the minimization of the makespan of the dependence graph. The makespan is the total execution time of the whole graph. The dependence graph that is fed as input to the scheduling algorithm is a DAG, therefore, it represents a partial order relationship in the execution of the operations. The scheduling algorithm makes decisions on mapping the operations to the cores while respecting this partial order and trying to minimize the total execution time of the dependence graph. In addition to the execution time of the operations, the scheduling algorithm has to take into considerations, the cost of inter-core synchronization. The scheduling problem can be stated as an optimization problem as follows:

\begin{table}[h]
\centering
\begin{tabular}{l  l}
  \rule{0pt}{5ex}	
	\textit{Input} & Dpenendence graph of operations $G_F(V_F,A_F)$\\
	\rule{0pt}{5ex}									  
	
  \textit{Output} & Offline Schedule of operations on multi-core processor\\
	\rule{0pt}{5ex}									  
  
	\textit{Find} & Mapping of operations to cores, $\alpha: V \rightarrow P$\\
	\rule{0pt}{5ex}
                & Assignment of start times to operations, $\beta: V \times P \rightarrow \mathbb{N}$\\
	\rule{0pt}{5ex}
	
	\textit{Minimize} & Makespan of the graph $P = max(E(o_i))_{o_i \in V}$\\
	\rule{0pt}{5ex}									 
	
	\textit{Subject to} & Precedence constraints of the graph $G_F(V_F,A_F)$\\
										 
	
\end{tabular}
\end{table}

\subsection{Resolution using Linear Programming}

In this section, we give our ILP formulation of the task scheduling problem for the acceleration of FMU co-simulation.

%\subsubsection{Variables and constants}
%
%Tables \ref{tab:varilpsched} and \ref{tab:consilpsched} summarize the variables and the constants that are used in the ILP formulation of the task scheduling problem for the acceleration of FMU co-simulation.
%
%\begin{table}
%\caption{Variables used in the ILP formulation of the task scheduling problem for the acceleration of FMU co-simulation}
%\centering
%\label{tab:varilpsched}
%\begin{tabular}{c c}
%\toprule
%Variable & Type \\
%\midrule
 %$x(o_i)$ & Binary  \\
%$S(o_i)$ & Integer   \\
%$E(o_i)$ & Integer  \\
%$sync_{ijp}$ & Binary   \\
%$b_{ijp}$ & Binary  \\
%$Q_{ip}$ & Integer  \\
%$V_{ip}$ & Binary  \\
%$mkp$ & Integer  \\
%
%\bottomrule
%\end{tabular}
%\end{table}
%
%\begin{table}
%\caption{Constants used in the ILP formulation of the task scheduling problem for the acceleration of FMU co-simulation}
%\centering
%\label{tab:consilpsched}
%\begin{tabular}{c c}
%\toprule
%Constant & Type \\
%\midrule
%
%$M$ & Integer  \\
%$C(o_i)$ & Integer  \\
%
%\bottomrule
%\end{tabular}
%\end{table}

\subsubsection{Constraints}

We define the decision binary variables $x_{ij}$ which indicate whether the operation $o_i$ is allocated to core $p_j$ or not. Expression \ref{sched:const_1} gives the constraint that each operation has to be allocated to one and only one core.

\begin{equation}
\forall\ o_i \in V, \sum_{p_j \in P}x_{ij}=1
\label{sched:const_1}
\end{equation}

The end time of each operation $o_i$ is computed using the expression \ref{sched:const_2}

\begin{equation}
\forall o_i \in V, E(o_i) = S(o_i) + C(o_i)
\label{sched:const_2}
\end{equation}

For operations that are allocated to the same core and that are completely independent, i.e. no path exists between them, we have to ensure that they are executed in non overlapping time intervals. Expressions \ref{sched:const_11} and \ref{sched:const_12} capture this constraint. $b_{ij}$ is a binary variable that is set to one if $o_i$ is executed before $o_j$.

\begin{equation}
\forall p \in P, \forall\ o_i \in V, \forall\ o_j \in V, (o_i,o_j), (o_j,o_i) \notin A_F, E(o_i) \leq S(o_j) + M \times (3 - x_{ip} - x_{jp} - b_{ij}) 
\label{sched:const_11}
\end{equation}

\begin{equation}
\forall p \in P, \forall\ o_i \in V, \forall\ o_j \in V, (o_i,o_j), (o_j,o_i) \notin A_F, E(o_j) \leq S(o_i) + M \times (2 - x_{ip} - x_{jp} + b_{ij}) 
\label{sched:const_12}
\end{equation}

The cost of synchronization is taken into account according to the synchronization model described in chapter \ref{ch:3-state}. In other words, a synchronization cost is introduced in the computation of the start time of an operation $o_j$, if it has a predecessor that is allocated to a different core and if its start time is the earliest among the successors of this predecessor that are allocated to the same core as the operation $o_j$. $sync_{ijp}$ is a binary variable which indicates whether synchronization is needed between $o_i$ and $o_j$ if $o_j$ is allocated to $p$. Therefore, $sync_{ijp} = 1\ \text{iff}\ \alpha(o_j)=p\ \text{and}\ \alpha(o_i)\neq p\  \text{and}\ S(o_j) = max_{o_{j'} \in succ(o_i)\ \text{and}\ \alpha(o_{j'}) = p}(S(o_{j'}))$. Expressions \ref{sched:const_3} and \ref{sched:const_4} capture this constraint. $V_{ip}$ is a binary variable that is set to one only if $\alpha(o_i) \neq p$. It is used to define for which cores a synchronization is needed between $o_i$ and its successors, in other words, if the successor is allocated to the same core as $o_i$, no synchronization is needed. Expressions \ref{sched:const_5} and \ref{sched:const_6} capture this constraint. Variable $Q_{ip}$ denotes the earliest start time among the start times of all successors of $o_i$ that are allocated to processor $p$. It is computed using expressions \ref{sched:const_7} and \ref{sched:const_8}. 


\begin{equation}
\forall o_i \in V, \sum_{\forall p \in P, \forall o_j \in pred(o_i)}sync_{ijp}= V_{ip}
\label{sched:const_3}
\end{equation}

\begin{equation}
\forall o_i \in V, \forall o_j \in succ(o_i), sync_{ijp} \leq x_{jp}: \forall o_i \in V
\label{sched:const_4}
\end{equation}

\begin{equation}
\forall o_i \in V, \forall o_j \in succ(o_i), V_{ip} \geq x_{jp} - x_{ip}: \forall o_i \in V
\label{sched:const_5}
\end{equation}

\begin{equation}
 \forall o_i \in V, V_{ip} \leq \sum_{\forall o_j \in succ(o_i)}\big(x_{jp} - x_{ip}\big)
\label{sched:const_6}
\end{equation}

\begin{equation}
\forall o_i \in V, \forall o_j \in succ(o_i), Q_{ip} \leq S(o_j) + M \times (1-x_{jp})
\label{sched:const_7}
\end{equation}

\begin{equation}
\forall o_i \in V, \forall o_j \in succ(o_i), Q_{ip} \geq S(o_j) - M \times (1-sync_{ijp})
\label{sched:const_8}
\end{equation}

The start time of each operation is computed using expression \ref{sched:const_9}. The synchronization cost is introduced taking into account the synchronizations with all predecessors of $o_j$ that are allocated to different cores. 

\begin{equation}
\forall o_j \in V, \forall o_i \in pred(o_j), S(o_j) \geq \Big[E(o_i) + \sum_{\forall p \in P, \forall o_{i'} \in pred(o_j)}sync_{ijp}\times synCost\Big]
\label{sched:const_9}
\end{equation}

The makespan is equal to the latest end time among the end times of all the operations as captured by expession \ref{sched:const_10}

\begin{equation}
\forall o_i \in V, mkp \geq E(o_i) 
\label{sched:const_10}
\end{equation}

\subsubsection{Objective function}

The objective of this linear program is to minimize the makespan of the dependence graph.

\begin{equation}
min(mkp)
\label{sched:obj}
\end{equation}


\subsection{Multi-core Scheduling Heuristic}

Multi-core scheduling problems are known to be NP-hard resulting in exponential resolution times when exact algorithms are used. Heuristics have been extensively used in order to solve multi-core scheduling problems. In most situations they lead to results of good quality in practicle resolution times. In particular, list heuristics presented in chapter \ref{ch:2-bkgnd} are widely used in the context of offline multi-core scheduling.

A variety of list multi-core scheduling heuristics exist in the literature and each heuristic may be suitable for some specific kinds of multi-core scheduling problems. We detail in this section a heuristic that we have chosen to apply on the final graph $G_F(V_F,A_F)$ in order to minimze its makespan. Because of the number of fine-grained operations, and since the execution times and the dependencies between the operations are known before runtime, it is more convenient to use an offline scheduling heuristic which has the advantage of introducing lower overhead than online scheduling heuristics. We use an offline scheduling heuristic similar to the one proposed in \cite{grandpierre:1999} which is a fast greedy algorithm whose cost function corresponds well to our minimization objective. In accordance with the principle of list scheduling heuristics, this heuristic is priority-based, i.e. it builds a list of operations that are ready to be scheduled, called candidate operations and selects one operation based on the evaluation of the cost function. We denote by $\rho$ the cost function and call it the schedule pressure. It expresses the degree of criticality of scheduling an operation. The schedule pressure of an operation is computed using its flexibility and the penalty of scheduling which refers to the increase in the critical path resulting from scheduling an operation.  

The heuristic considers the different timing attributes of each operation $o_i \in V_F$ in order to compute a schedule that minimizes the makespan of the graph. The heuristic schedules the operations of the graph $G_F(V_F,A_F)$ on the different cores iteratively and aims at minimizing the schedule pressure of an operation on a specific core. %Let $P^{n}(o_i,p_j)$ be the schedule pressure 
The heuristic updates the set of candidate operations to be scheduled at each iteration. An operation is added to the set of candidate operations if it has no predecessor or if all its predecessors have already been scheduled. For each candidate operation, the schedule pressure is computed on each core and the operation is allocated to its best core, the one that minimizes the pressure. Then, a list of candidate operation-best core pairs is obtained. Finally, the operation with the largest pressure on its best core is selected and scheduled. Synchronization operations are added between the scheduled operation and all its predecessors that were allocated to different cores. The heuristic repeats this procedure and finally stops when all the operations have been scheduled.   

\begin{algorithm}[!htp]		
	  Initialization\;
		Set $\Omega$ the set of all the operations\;  
		Set $P$ the set of all the available cores\; 
 		Set $O$ the set of operations without predecessors\;  		
 		\While{$\O \neq \emptyset$}
		{
 			\ForEach{operation $o_i \in O$} 
			{
 				Set $\sigma$ to $\infty$; (cost of $o_i$ is set to the maximum value)\;
 				\ForEach{$p \in P$}
				{
  				$S'(o_i) \leftarrow max(S(o_i) , L_p)$; (new start time of $o_i$ when executed on $p$)\;
  				$\sigma' \leftarrow S'(o_i) + C(o_i) + \overline{E}(o_i) - R$; (cost of $o_i$ when executed on $p)$\;
  				\If{$\sigma' < \sigma$}
					{
  					Set $\sigma \leftarrow \sigma'$\;
  					Set $BestCore(o_i) \leftarrow p$\;
  				}
  			}
  		 }
  		 Find $o_{i'}$ with maximal cost $\sigma$ in $O$\; 
  		 Schedule $o_{i'}$ on its core $\mathrm{BestCore}(o_{i'})$\;
  		 Set $p' := \mathrm{BestCore}(o_{i'})$\;
  		 $L_{\mathrm{p'}} := L_{\mathrm{p'}} + C(o_{i'})$; (Advance the time of $p'$)\;
  		 Remove $o_{i'}$ from the set $O$\;
  		 Add to the set $O$ all successors of $o_{i'}$ for which all predecessors are already scheduled\;
		}
	\caption{Multi-core scheduling heuristic}
	\label{algo:sched}
\end{algorithm}

\subsubsection{Complexity}

\subsection{Code Generation}

\section{Scheduling of FMU Co-simulation with Real-time Constraints}


